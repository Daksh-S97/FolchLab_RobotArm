{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deps.dobot_api import DobotApiDashboard, DobotApiMove # deps is a folder and we are importing 2 classes from a file within the folder, these classes \n",
    "# allow us to control the robot informationally and movement oriented \n",
    "from deps import utils # importing the module utils from a file within the folder deps, don't import all files from deps, just utils\n",
    "from deps import cv_core # this module houses all of the functions that are controlling and dealing with the camera and what it's doing\n",
    "import numpy as np # numpy is a module, we want lots of functions from numpy so we import full module\n",
    "import matplotlib.pyplot as plt # module that allows plotting, not used \n",
    "import cv2 # open cv, computer vision module with own GUI\n",
    "from pynput import keyboard # module allows you to get callbacks from keyboard press (control robot using arrow keys)\n",
    "import time # this module allows you to control timings \n",
    "import ipyparallel as ipp # module that allows code to be launched in parallel with other code\n",
    "import random\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.51s/engine]\n"
     ]
    }
   ],
   "source": [
    "rc = ipp.Cluster(n=1).start_and_connect_sync() # use this to move the robot with arrow keys and view camera feed at the same time \n",
    "e0 = rc[0]\n",
    "e0.block = False\n",
    "e0.activate('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash = DobotApiDashboard('192.168.1.6', 29999) # dash is the object that is connected to the robot and gets information from the dashboard\n",
    "move = DobotApiMove('192.168.1.6', 30003) # the object that allows you to control the movement of the robot\n",
    "# both classes we input ip address and port that we are communicating with \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},EnableRobot();'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.ClearError() # dash is an object and ClearError is a method in dash that we are calling, clears error and warning when robot freezes and turns red\n",
    "dash.EnableRobot() # enables the robot for use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},DisableRobot();'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.DisableRobot() # disables the robot, white letters below is the robot's response as a String, 0 means that everything is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n",
      "Special key pressed: Key.esc\n"
     ]
    }
   ],
   "source": [
    "keys = utils.Keyboard(dash) # initializing the class Keyboard from the module (file that houses functions (methods) and classes utils and we are passing the parameter dash\n",
    "# we are giving the class Keyboard a connection to the robot which is called dash, dash is an object of the class dashboard\n",
    "keys.execute() # Keyboard has a method called execute, use this to record the position of the robot by pressing s. if finished press esc\n",
    "# we want to find corners of well plate so we record the position of the 4 corners and use this information later, just one use of execute of class keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 221.360791, -149.246332,  -72.163689,   -0.881416]),\n",
       " array([229.452076, -90.066315, -70.084389,  11.678659]),\n",
       " array([ 326.035731, -151.958795,  -70.521561,    8.118006]),\n",
       " array([333.893559, -90.564967, -71.46936 ,  17.934322])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.coords # list of arrays with recorded coordinates at positions where s was pressed, coords is an attribute of keys (a variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [np.array([280,  40, -90,  0]), # list of positions from coords of 4 corners around petri dish, called anchors for the laser\n",
    "           np.array([230,  37, -90,  0]),\n",
    "           np.array([220, -14, -90,  0]),\n",
    "           np.array([270, -15, -90,  0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell calculates the grid for the 96 well plate\n",
    "well_plate = utils.assign_corners(keys.coords, reverse=True) # assign_corners is a method in the module utils \n",
    "left_side_points = np.linspace(well_plate['ul'], well_plate['ll'], 12)[:,:2]\n",
    "right_side_points = np.linspace(well_plate['ur'], well_plate['lr'], 12)[:,:2]\n",
    "grid = []\n",
    "for i in range(len(left_side_points)):\n",
    "    x1, y1 = left_side_points[i]\n",
    "    x2, y2 = right_side_points[i]\n",
    "    a = (x2-x1)/(y2-y1)\n",
    "    b = x1 - a*y1\n",
    "    ys = np.linspace(y1,y2,8) \n",
    "    xs = a*ys + b\n",
    "    grid += (list(zip(xs,ys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('well_plate_96.npy',np.array(grid)) # saves well plate grid into a file named 'well_plate_96.npy', we want to save this so we can use later and not repeat process\n",
    "#np.load('well_plate_96.npy')\n",
    "#np.save('well_plate_96_tk.npy',np.array(grid)) # To prevent the guy developing the gui from messing up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m move\u001b[39m.\u001b[39mMovL(x,y,\u001b[39m-\u001b[39m\u001b[39m38\u001b[39m,\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m move\u001b[39m.\u001b[39mSync()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m move\u001b[39m.\u001b[39;49mMovL(x,y,\u001b[39m-\u001b[39;49m\u001b[39m80\u001b[39;49m,\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m move\u001b[39m.\u001b[39mSync()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m move\u001b[39m.\u001b[39mMovL(x,y,\u001b[39m-\u001b[39m\u001b[39m38\u001b[39m,\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:468\u001b[0m, in \u001b[0;36mDobotApiMove.MovL\u001b[0;34m(self, x, y, z, r)\u001b[0m\n\u001b[1;32m    465\u001b[0m string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMovL(\u001b[39m\u001b[39m{:f}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{:f}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{:f}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{:f}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    466\u001b[0m     x, y, z, r)\n\u001b[1;32m    467\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_data(string)\n\u001b[0;32m--> 468\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_reply()\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:159\u001b[0m, in \u001b[0;36mDobotApi.wait_reply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait_reply\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    Read the return value\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_dobot\u001b[39m.\u001b[39;49mrecv(\u001b[39m1024\u001b[39;49m)\n\u001b[1;32m    160\u001b[0m     data_str \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(data, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m     \u001b[39m#self.log(f'Receive from 192.168.1.6:{self.port}: {data_str}')\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid = np.load('well_plate_96.npy')\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "for coord in grid:\n",
    "    x,y = coord\n",
    "    move.MovL(x,y,-38,0)\n",
    "    move.Sync()\n",
    "    move.MovL(x,y,-80,0)\n",
    "    move.Sync()\n",
    "    move.MovL(x,y,-38,0)\n",
    "    move.Sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n"
     ]
    }
   ],
   "source": [
    "manmove = utils.ManualMove(move, dash) # used to control robot with keyboard, uses key presses to control robot \n",
    "manmove.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([259.140423, -25.900747, -38.368862,   0.      ]),\n",
       " array([311.43616 , -25.116732, -38.372147,   0.      ]),\n",
       " array([319.415466,  36.8682  , -38.376747,   0.      ]),\n",
       " array([273.618713,  36.862676, -38.382015,   0.      ])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manmove.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_offset = (manmove.coords[0] - np.array([250, 0, -90, 0]))[:2]\n",
    "np.save('base_offset.npy', base_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_rotation(x, y, angle):\n",
    "    xPrime = x*np.cos(angle) - y*np.sin(angle)\n",
    "    yPrime = x*np.sin(angle) + y*np.cos(angle)\n",
    "\n",
    "    return xPrime, yPrime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dash\u001b[39m.\u001b[39;49mClearError()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dash\u001b[39m.\u001b[39mEnableRobot()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m move\u001b[39m.\u001b[39mMovL(\u001b[39m250\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m90\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:218\u001b[0m, in \u001b[0;36mDobotApiDashboard.ClearError\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mClearError()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_data(string)\n\u001b[0;32m--> 218\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_reply()\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:159\u001b[0m, in \u001b[0;36mDobotApi.wait_reply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait_reply\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    Read the return value\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_dobot\u001b[39m.\u001b[39;49mrecv(\u001b[39m1024\u001b[39;49m)\n\u001b[1;32m    160\u001b[0m     data_str \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(data, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m     \u001b[39m#self.log(f'Receive from 192.168.1.6:{self.port}: {data_str}')\u001b[39;00m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "move.MovL(250, 0, -90, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_pose(dash, angle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px0\n",
    "from deps import utils\n",
    "from deps.dobot_api import DobotApiDashboard, DobotApiMove\n",
    "dash = DobotApiDashboard('192.168.1.6', 29999)\n",
    "move = DobotApiMove('192.168.1.6', 30003)\n",
    "manmove = utils.ManualMove(move, dash)\n",
    "manmove.execute()\n",
    "coords = manmove.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = e0.pull('coords')\n",
    "coords = ar.get()\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@586.455] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200'])\n",
    "cv_core.video_test(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('anchors.npy', manmove.coords)\n",
    "np.save('anchors_tk.npy', manmove.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = np.load('anchors_tk.npy')\n",
    "#np.save('anchors_tk.npy', anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258.384153, -28.007687, -38.011772,   0.      ],\n",
       "       [310.115155, -25.357152, -38.026409,   0.      ],\n",
       "       [319.175741,  36.666989, -38.029057,   0.      ],\n",
       "       [271.662783,  36.660358, -38.036018,   0.      ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Petri Dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@73.668] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@76.352] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@78.649] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@80.869] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "#anchors = keys.coords\n",
    "anchors = np.load('anchors_tk.npy')\n",
    "# anchors = [np.array([307.315193, -13.865066, -81,  -3.484534]),\n",
    "#  np.array([316.442224,  49.591866, -81,  -3.484533]),\n",
    "#  np.array([268.040607,  48.172406, -81,  -3.484533]),\n",
    "#  np.array([260.923249, -14.987419, -81,  -3.484531])]\n",
    "\n",
    "# anchor positions, positions of the laser that the camera recognizes to create a transformation matrix\n",
    "# allows you to transform pixel coordinates of an object to actual robot coordinates \n",
    "\n",
    "# computer vision stuff\n",
    "\n",
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy')\n",
    "dist = np.load('./cam_matrices/dist.npy')\n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy')\n",
    "template = cv2.imread('template.png', 0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap = cv_core.set_res(cap, cv_corfind_contourse.camera_res_dict['1200'])\n",
    "\n",
    "# cv2.namedWindow('frame',  cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "\n",
    "\n",
    "recorded = []\n",
    "for idx, anchor in enumerate(anchors):\n",
    "    x,y,z,r = anchor\n",
    "    move.MovL(x,y,z,r)\n",
    "    move.Sync()\n",
    "\n",
    "    #while(True):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200'])\n",
    "\n",
    "    cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # creating a GUI window cv2 is a module called open cv which has all the methods related to computer vision\n",
    "    cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "    ret, frame = cap.read() # how to access camera information, gives single frame that has been captured by the camera at the time of execution\n",
    "    # gives ret which is a boolean (true/false) true if frame captured, frame gives a numpy array that is basically the image (if color, 3 channel array rgb)\n",
    "    \n",
    "    \n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix) # need these 3 parameters to undistort the frame and give a new undistorted frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    plot_img = frame.copy() # create a copy of the variable frame (create a copy of the image)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # turn frame to grayscale \n",
    "    (minVal, maxVal, minLoc, maxLoc)=cv2.minMaxLoc(gray) # gives location of minimum and maximum pixel value, gives coordinates in pixels\n",
    "    a, b = maxLoc # unpack max location into 2 variables, the x and y (a and b) in pixels\n",
    "    \n",
    "    top_left = (a-w, b-h) # make white rectangle around desired maximum pixel values\n",
    "    bottom_right = (a+w, b+h)\n",
    "\n",
    "    mask = np.zeros_like(frame) # brightest part not always the center point, we want to isolate the bright spot, we apply a mask onto the image \n",
    "    # we take a grayscale image and we apply a mask around the bright spot, we create absolute black image \n",
    "    cv2.rectangle(mask,top_left, bottom_right, (255,255,255), -1) # we create filled white rectangle around the bright spot \n",
    "    cv2.rectangle(plot_img,top_left, bottom_right, (255,255,255), 2) # puts white hollow rectangle onto the visual image \n",
    "    result = cv2.bitwise_and(frame.astype('uint8'), mask.astype('uint8')) # we multiply the frame by the mask which leaves only the bright spot\n",
    "    gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) # result given in rgb and we want to go to grayscale, gives one grayscale array instead of 3 BGR\n",
    "    ret, thresh = cv2.threshold(gray_result,240,255,cv2.THRESH_BINARY) # apply thresholding to take brightest desired pixels and ignore all other values\n",
    "    M = cv2.moments(thresh) # this is what is finding the center by calculating the moments of the bright blob, calculates center of mass of a pixel blob\n",
    "    if M[\"m00\"] != 0:\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cv2.circle(plot_img, (cX, cY), 5, (0, 255, 0), 2) # drawing a circle around the brightest blob for visual purposes \n",
    "        recorded.append((cX, cY)) # we record the x and y pixel values of the center of the blob so we can map the location onto the robots coordinates, at that point\n",
    "        \n",
    "\n",
    "    cv2.imshow('frame',plot_img) # shows the image\n",
    "    #cv2.imwrite(f'anchor_{idx}.jpg', plot_img)\n",
    "    cv2.waitKey(0) # index zero wait key, tells the computer to wait for any key press before continuing execution\n",
    "    cap.release() # releases the camera from control of the computer, disconnects the camera from the computer and empties memory\n",
    "   \n",
    "cv2.destroyAllWindows() # when 4 loop finishes it destroys (closes) the graphical window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_pose(dash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Pipette down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "move.MovL(315.233371,  49.014043, -97.242516,  -1.563194)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the cell that calculates the transformation matrix \n",
    "xys = [(arr[0], arr[1]) for arr in anchors]\n",
    "robot_coor = utils.assign_corners(xys, reverse=True) # assign corners to the robot coordinates at the 4 corner positions \n",
    "pix_coor = utils.assign_corners(recorded) # assign corners to the pixel coordinates at the 4 corner positions \n",
    "\n",
    "features_mm_to_pixels_dict = {} # setting up an empty dictionary to store the mapping of the corners from coordinate to pixel\n",
    "for key, value in robot_coor.items():\n",
    "    features_mm_to_pixels_dict[value] = pix_coor[key]\n",
    "\n",
    "\n",
    "tf_mtx = cv_core.compute_tf_mtx(features_mm_to_pixels_dict) # method of cv_core module that calculates transformation matrix\n",
    "np.save('tfm_mtx.npy', tf_mtx)\n",
    "# takes the dictionary and solves the system of linear equations that gives the transformation matrix and gives the actual relation between the pixels and millimeters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "move.JointMovJ(-30,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_z = np.mean(anchors[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.610901749999996"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-37 - (calibration_z + 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43.38909825"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(anchors[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_mtx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tf_mtx\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_mtx' is not defined"
     ]
    }
   ],
   "source": [
    "tf_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuboid transfer with Snapshot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},EnableRobot();'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discerning isolated cuboids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mtx = np.load('tfm_mtx.npy')\n",
    "\n",
    "def calc_centers(conts):\n",
    "    centers = []\n",
    "    for i in range(len(conts)):\n",
    "        M = cv2.moments(conts[i])\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        X, Y, _ = tf_mtx @ (cX, cY, 1)\n",
    "        centers.append([X,Y])\n",
    "    return centers  \n",
    "def mindis(centers):\n",
    "    dis = collections.defaultdict(lambda: np.inf)\n",
    "    for i in range(len(centers)):\n",
    "        x,y = centers[i]\n",
    "        #print(x,y)\n",
    "        for j in range(i+1,len(centers)):\n",
    "            x1,y1 = centers[j]\n",
    "            distance = math.sqrt(abs(x1-x) ** 2 + abs(y1-y) ** 2)\n",
    "            dis[i] = min(dis[i], distance)\n",
    "            dis[j] = min(dis[j],distance)\n",
    "    return list(sorted(dis.items(), key = lambda item : item[1], reverse = True))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@403.209] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "(97, 2.980244117534299)\n",
      "[[[730 412]]\n",
      "\n",
      " [[729 413]]\n",
      "\n",
      " [[728 413]]\n",
      "\n",
      " [[728 415]]\n",
      "\n",
      " [[729 414]]\n",
      "\n",
      " [[732 414]]\n",
      "\n",
      " [[733 413]]\n",
      "\n",
      " [[732 412]]]\n",
      "51\n",
      "(50, 3.9285694026527898)\n",
      "[[[447 741]]\n",
      "\n",
      " [[446 742]]\n",
      "\n",
      " [[446 744]]\n",
      "\n",
      " [[448 744]]\n",
      "\n",
      " [[449 743]]\n",
      "\n",
      " [[449 741]]]\n",
      "49\n",
      "(48, 3.9285694026527898)\n",
      "[[[447 741]]\n",
      "\n",
      " [[446 742]]\n",
      "\n",
      " [[446 743]]\n",
      "\n",
      " [[447 744]]\n",
      "\n",
      " [[448 744]]\n",
      "\n",
      " [[449 743]]\n",
      "\n",
      " [[449 741]]]\n",
      "49\n",
      "(48, 1.0719704800196144)\n",
      "[[[607 840]]\n",
      "\n",
      " [[607 843]]\n",
      "\n",
      " [[609 845]]\n",
      "\n",
      " [[610 845]]\n",
      "\n",
      " [[611 844]]\n",
      "\n",
      " [[611 842]]\n",
      "\n",
      " [[610 841]]\n",
      "\n",
      " [[610 840]]]\n",
      "51\n",
      "(50, 3.988614621289119)\n",
      "[[[447 741]]\n",
      "\n",
      " [[446 742]]\n",
      "\n",
      " [[446 744]]\n",
      "\n",
      " [[448 744]]\n",
      "\n",
      " [[449 743]]\n",
      "\n",
      " [[449 741]]]\n",
      "46\n",
      "(45, 5.344085127279317)\n",
      "[[[607 840]]\n",
      "\n",
      " [[606 841]]\n",
      "\n",
      " [[606 842]]\n",
      "\n",
      " [[609 845]]\n",
      "\n",
      " [[610 845]]\n",
      "\n",
      " [[611 844]]\n",
      "\n",
      " [[611 842]]\n",
      "\n",
      " [[610 841]]\n",
      "\n",
      " [[610 840]]]\n"
     ]
    }
   ],
   "source": [
    "grid = np.load('well_plate_96.npy')\n",
    "move.JointMovJ(-30,0,0,0)\n",
    "tf_mtx = np.load('tfm_mtx.npy')\n",
    "anchors = np.load('anchors_tk.npy')\n",
    "\n",
    "cont = cv_core.Contours() # define class of methods for cuboid detection, initialize class\n",
    "offset = 60 # create smaller inner circle in petri dish to locate cuboids \n",
    "cap = cv2.VideoCapture(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200']) # sets the resolution of the camera to 1200 x 1600\n",
    "\n",
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy') # uploading the camera matrices for the calibration of the camera for undistortion\n",
    "dist = np.load('./cam_matrices/dist.npy') \n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy') \n",
    "\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011) # set resolution of window\n",
    "idx = 0\n",
    "\n",
    "calibration_z = np.mean(anchors[:,2])\n",
    "z_offset = 35\n",
    "\n",
    "while(True): # we want a video stream so we want a while loop to continuously take new images until loop is broken\n",
    "    \n",
    "    for i in range(5):   # TODO: Test with this and see if you still need five presses on the spacebar # Sarmad Hassan\n",
    "        ret, frame = cap.read()\n",
    "    #ret, frame = cap.read() \n",
    "    \n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "\n",
    "    pt = cont.find_contours(frame, 10, offset) # takes the frame and looks for the circle of the petri dish, also looks for the cuboids \n",
    "        \n",
    "    a,b,r = pt # gives the x y coordinates and the radius of the circle\n",
    "    plot_img = frame.copy() # create a copy of the frame so things can be drawn on it without altering original image\n",
    "\n",
    "    cv2.circle(plot_img, (a, b), r, (3, 162, 255), 2) # circles being drawn on image to locate petri dish\n",
    "    cv2.circle(plot_img, (a, b), 1, (0, 0, 255), 3)\n",
    "    cv2.circle(plot_img, (a, b), r - offset, (0, 255, 0), 2) \n",
    "\n",
    "    cv2.drawContours(plot_img, cont.singular, -1,(0,255, 0),2) # two lists of contours (cuboid contours) that we draw on the plotting image\n",
    "    cv2.drawContours(plot_img, cont.clusters, -1,(0,0,255),2) # we do this to distinguish between clusters and cuboids\n",
    "\n",
    "    cv2.putText(plot_img, f\"Found: {len(cont.singular)}\", (25,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2) # how many cuboids it sees\n",
    "    cs = calc_centers(cont.singular)\n",
    "    ds = mindis(cs)\n",
    "    # print(len(cont.singular))\n",
    "    # print(max(ds))\n",
    "    print(cont.singular[ds[0][0]])\n",
    "    cv2.drawContours(plot_img, [cont.singular[ds[0][0]]],-1,(255,0,0),2)\n",
    "    \n",
    "    cv2.imshow('frame',plot_img) # this just displays the image \n",
    "    \n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(0)\n",
    "    if k == ord('q'): # if you press q, the while loop will break and the video and locating will stop, then the camera is released and windows destroyed\n",
    "        break\n",
    "    elif k == ord('e'):\n",
    "        #print(len(cont.singular))\n",
    "        if len(cont.singular) >= 1:\n",
    "            # center = cont.contour_centers(cont.singular)[0]            \n",
    "            #center = random.choice(cont.contour_centers(cont.singular))\n",
    "            #X, Y, _ = tf_mtx @ (center[0], center[1], 1)\n",
    "            \n",
    "            X, Y = cs[ds[0][0]]\n",
    "            move.MovL(X, Y, calibration_z + z_offset, 0)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(0, dash, move)\n",
    "            # utils.correct_J4_angle(-360, dash, move)\n",
    "            # utils.correct_J4_angle(0, dash, move)\n",
    "            move.RelMovL(0,0, -z_offset) #(0,0,-36)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(120, dash, move)\n",
    "            move.RelMovL(0,0,z_offset) #(0,0,36) #24 works!!\n",
    "            move.Sync()\n",
    "            x,y = grid[idx]\n",
    "            idx += 1\n",
    "            move.MovL(x,y,calibration_z + z_offset, 120)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(120, dash, move)\n",
    "            move.RelMovL(0,0,-28) #(0,0,-27)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(-100, dash, move)\n",
    "            move.RelMovL(0,0, 28) #(0,0,-27)\n",
    "            move.Sync()\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@630.335] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cont = cv_core.Contours() # define class of methods for cuboid detection, initialize class\n",
    "offset = 40 # create smaller inner circle in petri dish to locate cuboids \n",
    "cap = cv2.VideoCapture(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1944'])\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    plot_img = frame.copy()\n",
    "    mask = np.zeros_like(frame)\n",
    "\n",
    "    a, b, _ = frame.shape\n",
    "    mask = cv2.circle(mask, (round(b/2), round(a/2)), 700, (255, 255, 255), -1)\n",
    "    masked = cv2.bitwise_and(frame.astype('uint8'), mask.astype('uint8'))\n",
    "\n",
    "    plot_mask = cv2.circle(mask, (round(b/2), round(a/2)), 800, (255, 255, 255), -1)\n",
    "    plot_img = cv2.bitwise_and(plot_img.astype('uint8'), plot_mask.astype('uint8'))\n",
    "    cv2.circle(plot_img, (round(b/2), round(a/2)), 700, (0, 0, 255), 3)\n",
    "    gray = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,29,5)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    # dilation = cv2.dilate(thresh,kernel,iterations = 1)\n",
    "    # erosion = cv2.erode(thresh,kernel,iterations = 1)\n",
    "    res = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "            res, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = cont.filter_contours(contours, 60, 500)\n",
    "\n",
    "    \n",
    "    cv2.drawContours(plot_img, contours, -1,(0,255, 0),2)\n",
    "    \n",
    "    for c in contours:\n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"]) # the function moments gives a mysterious dictionary with elements of matrix, it seems that you gotta divide one element by another to get x&y\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cv2.putText(plot_img, f\"{cv2.contourArea(c)}\", (cX - 20, cY - 20), # putting the area of the cuboids onto the screen as text next to the cuboid\n",
    "              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('frame',plot_img)\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == ord('q'): # if you press q, the while loop will break and the video and locating will stop, then the camera is released and windows destroyed\n",
    "        break  \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b, _ = frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1944, 2592)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()  \n",
    "cap.release()  \n",
    "cv2.imshow('frame',frame) # this just displays the image \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011) # set resolution of window\n",
    "\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #ret,res = cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV)\n",
    "ret,res = cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV)\n",
    "th3 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY_INV,11,9)\n",
    "\n",
    "cv2.imshow('frame',th3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuboid Recognition and Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@375.238] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cont = cv_core.Contours() # define class of methods for cuboid detection, initialize class\n",
    "tf_mtx = np.load('tfm_mtx.npy')\n",
    "def on_change(val): pass\n",
    "\n",
    "offset = 40 # create smaller inner circle in petri dish to locate cuboids \n",
    "cap = cv2.VideoCapture(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200']) # sets the resolution of the camera to 1200 x 1600\n",
    "\n",
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy') # uploading the camera matrices for the calibration of the camera for undistortion\n",
    "dist = np.load('./cam_matrices/dist.npy') \n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy') \n",
    "\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011) # set resolution of window\n",
    "cv2.createTrackbar('Manual Lock', 'frame', 0, 1, on_change) # create trackbar between values of 0 and 1, basically a switch (manual lock of the circle recognition)\n",
    "# stops trying to recognize the petri dish (locked) increases performance of more fps because it recognizes a lot of circles which takes time so this locks it \n",
    "# circle recognition needs optimizing \n",
    "cv2.createTrackbar('Mask Offset', 'frame', offset, 150, on_change) # second trackbar allows control of offset which changes the size of the petri dish detection circle\n",
    "cv2.setMouseCallback('frame', cont.mousecallback) # set a callback function for double clicks of the mouse, this allows us to select cuboids by double clicking\n",
    "# initializes a double click response to select a certain contour on the screen \n",
    "\n",
    "idx = 0 \n",
    "prev_point = (0,0,0)\n",
    "while(True): # we want a video stream so we want a while loop to continuously take new images until loop is broken\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "    val = cv2.getTrackbarPos('Manual Lock', 'frame') # checks position of trackbar for manual lock, if trackbar 1, then val = 1, this turns off circle detection\n",
    "    offset = cv2.getTrackbarPos('Mask Offset', 'frame') # the trackbar with the offset, changes the offset value for the circle\n",
    "    if val == 1:\n",
    "        cont.locked = True\n",
    "    else:\n",
    "        cont.locked = False\n",
    "\n",
    "    # if cont.best_circ is None:\n",
    "    #     while cont.best_circ is None:\n",
    "    #         pt = cont.find_contours(frame, 10, offset)\n",
    "    # else:\n",
    "    pt = cont.find_contours(frame, 10, offset) # 10 og,takes the frame and looks for the circle of the petri dish, also looks for the cuboids \n",
    "        \n",
    "    a,b,r = pt # gives the x y coordinates and the radius of the circle\n",
    "    plot_img = frame.copy() # create a copy of the frame so things can be drawn on it without altering original image\n",
    "    cv2.circle(plot_img, (a, b), r, (3, 162, 255), 2) # circles being drawn on image to locate petri dish\n",
    "    cv2.circle(plot_img, (a, b), 1, (0, 0, 255), 3)\n",
    "    cv2.circle(plot_img, (a, b), r - offset, (0, 255, 0), 2)\n",
    "    # print(cont.big_circ[2])\n",
    "    cv2.circle(plot_img, cont.big_circ[:2], int(cont.big_circ[2]), (0, 0, 255), 2)\n",
    "    cv2.putText(plot_img, f\"{cont.big_circ[2]*2}px = 60mm\", (cont.big_circ[0]-25, cont.big_circ[1] - cont.big_circ[2] - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2) # how to decide size of cuboids, use diameter of petri dish being 60 mm to approximate size of cuboids\n",
    "        # just a text sign around the biggest circle of the image (petri dish) saying that this circle is 60 mm\n",
    "    \n",
    "    cv2.drawContours(plot_img, cont.singular, -1,(0,255, 0),2) # two lists of contours (cuboid contours) that we draw on the plotting image\n",
    "    cv2.drawContours(plot_img, cont.clusters, -1,(0,0,255),2) # we do this to distinguish between clusters and cuboids \n",
    "\n",
    "    if cont.selected: # if we selected cuboids with the double click, we draw them in blue\n",
    "        cv2.drawContours(plot_img, cont.selected, -1,(255,0,0),2) # BGR, this is blue contour \n",
    "\n",
    "    for c in cont.singular: # we find the centers of the contours similar to how we found centers with the calibration step\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"]) # the function moments gives a mysterious dictionary with elements of matrix, it seems that you gotta divide one element by another to get x&y\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "        cv2.circle(plot_img, (cX, cY), 2, (0, 0, 255), -1) # just draw a cirlce around the contour \n",
    "        cv2.putText(plot_img, f\"{cX},{cY}\", (cX - 20, cY - 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(plot_img, f\"{cv2.contourArea(c)}\", (cX - 20, cY - 20), # putting the area of the cuboids onto the screen as text next to the cuboid\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
    "    #out.write(with_contours)\n",
    "\n",
    "    for c in cont.clusters: # same thing for clustes as above but no printed text for cuboid area or coordinate\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        # draw the contour and center of the shape on the image\n",
    "        #cv2.drawContours(plot_img, [c], -1, (0, 255, 0), 2)\n",
    "        cv2.circle(plot_img, (cX, cY), 2, (0, 0, 255), -1)\n",
    "        # cv2.putText(plot_img, f\"{cX},{cY}\", (cX - 20, cY - 20),\n",
    "        # cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "\n",
    "        # cv2.putText(plot_img, f\"{cv2.contourArea(c)}\", (cX - 20, cY - 20),\n",
    "        # cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 1)\n",
    "\n",
    "\n",
    "    if prev_point is pt:\n",
    "        idx += 1\n",
    "    else:\n",
    "        idx = 0\n",
    "    prev_point = pt\n",
    "\n",
    "\n",
    "    if idx >= 30: # if circle stays same for awhile then it will show as locked (30 frames the same)\n",
    "        message = 'LOCKED'\n",
    "        color = (0,255,0)\n",
    "    else:\n",
    "        message = 'SEARCHING' # more text messages \n",
    "        color = (0,0,255)\n",
    "\n",
    "    cv2.putText(plot_img, \"TARGET:\", (25,25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2) # text messages, target displays constantly\n",
    "    cv2.putText(plot_img, f\"{message}\", (125,25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2) # displays message locked or searching\n",
    "    cv2.putText(plot_img, f\"Found: {len(cont.singular)}\", (25,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2) # how many cuboids it sees\n",
    "\n",
    "    \n",
    "    cv2.imshow('frame',plot_img) # this just displays the image \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # if you press q, the while loop will break and the video and locating will stop, then the camera is released and windows destroyed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCaptrure(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200'])\n",
    "cv_core.video_test(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},EnableRobot();'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},Sync();'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "M = cv2.moments(cont.selected[0])\n",
    "cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "X, Y, _ = tf_mtx @ (cX, cY, 1)\n",
    "move.MovL(X, Y, -38, 0)\n",
    "move.Sync()\n",
    "#utils.correct_J4_angle(0, dash, move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[264.064392, -25.735942, -43.384838,  -9.996752],\n",
       "       [274.047377,  36.497396, -43.389351,  -9.996789],\n",
       "       [324.645768,  37.404662, -43.390736,  -9.996744],\n",
       "       [312.077032, -26.602958, -43.391468,  -9.996742]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manmove = utils.ManualMove(move, dash)\n",
    "manmove.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash.DisableRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.report_error(dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[466, 548]],\n",
       " \n",
       "        [[465, 549]],\n",
       " \n",
       "        [[467, 551]],\n",
       " \n",
       "        [[469, 551]],\n",
       " \n",
       "        [[470, 550]],\n",
       " \n",
       "        [[469, 549]],\n",
       " \n",
       "        [[467, 549]]], dtype=int32),\n",
       " array([[[582, 561]],\n",
       " \n",
       "        [[582, 565]],\n",
       " \n",
       "        [[585, 565]],\n",
       " \n",
       "        [[585, 562]],\n",
       " \n",
       "        [[584, 562]],\n",
       " \n",
       "        [[583, 561]]], dtype=int32),\n",
       " array([[[567, 608]],\n",
       " \n",
       "        [[565, 610]],\n",
       " \n",
       "        [[565, 611]],\n",
       " \n",
       "        [[566, 611]],\n",
       " \n",
       "        [[567, 612]],\n",
       " \n",
       "        [[569, 612]],\n",
       " \n",
       "        [[570, 611]],\n",
       " \n",
       "        [[570, 610]],\n",
       " \n",
       "        [[568, 608]]], dtype=int32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},DisableRobot();'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.DisableRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "dash.DisableRobot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating min distance between cuboids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont.singular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[315.63778026853527, 4.471045972871714]\n",
      "[313.6807555129855, 16.20140080253575]\n",
      "[306.98065684251276, 9.732800435430029]\n",
      "[305.40516214806377, 8.442112839675197]\n",
      "[306.2557234582784, 20.13631120485632]\n",
      "[305.7414366343428, 26.88510181410988]\n",
      "[300.0103422204099, 7.106969803091609]\n",
      "[300.08352959191336, 13.56727119385149]\n",
      "[288.02713277643625, -20.269226360163856]\n",
      "[289.55330916363994, -9.4264995996962]\n",
      "[295.1702680125258, 29.362269122232412]\n",
      "[286.7746896327764, -20.15945601575303]\n",
      "[289.60144233683843, 12.20400144233465]\n",
      "[284.4675277619208, -5.615355592554053]\n",
      "[282.62815586333176, 1.8996293658454348]\n",
      "[284.2721355033237, 26.037891719458067]\n",
      "[283.60716655510294, 25.859172845375205]\n",
      "[275.9829241582298, 11.63025279124303]\n",
      "[276.4241740064895, 15.932066255639107]\n",
      "[268.06138024520993, 5.458306005578756]\n",
      "[267.76932659553347, 4.244731302443711]\n",
      "[267.0782125679881, 5.002761288641871]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "centers = calc_centers(cont.singular)\n",
    "distances = mindis(centers)\n",
    "\n",
    "for i in range(len(distances)):\n",
    "    x,y = centers[distances[i][0]]\n",
    "    move.MovL(x, y, -58, 0)\n",
    "    move.Sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launches the cuboid transfer individual selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#centers_cuboids = cont.contour_centers(cont.singular)\n",
    "grid = np.load('well_plate_96.npy')\n",
    "centers_cuboids = cont.contour_centers(cont.selected)\n",
    "#cub_offset = np.load('offset.npy')\n",
    "#x_off_base, y_off_base = base_offset\n",
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "\n",
    "utils.default_pos(move)\n",
    "move.Sync()\n",
    "for idx, center in enumerate(centers_cuboids):\n",
    "    if idx == 96:\n",
    "        break # idx is index, enumerate takes an array and assigns indexes to each element of the array, each element in the array is a cuboid\n",
    "    X, Y, _ = tf_mtx @ (center[0], center[1], 1)\n",
    "    move.MovL(X, Y, -60, 0)\n",
    "    move.Sync()\n",
    "    # base_angle = utils.get_pose(dash, angle=True, verbose=False)[0]\n",
    "    # x_off, y_off = coordinate_rotation(y_off_base, x_off_base, base_angle)\n",
    "   \n",
    "    utils.correct_J4_angle(0, dash, move)\n",
    "    # utils.correct_J4_angle(-360, dash, move)\n",
    "    # utils.correct_J4_angle(0, dash, move)\n",
    "    move.RelMovL(0,0,-29)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,29)\n",
    "    # move.Sync()\n",
    "    # x,y = grid[idx]\n",
    "    # move.MovL(x,y,-60, 120)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,-23)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(-100, dash, move)\n",
    "    # move.RelMovL(0,0,23)\n",
    "    # move.Sync()\n",
    "    \n",
    "\n",
    "# utils.default_pos(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laser test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_cuboids = cont.contour_centers(cont.selected)\n",
    "grid = np.load('well_plate_96.npy')\n",
    "#centers_cuboids = cont.contour_centers(cont.selected)\n",
    "#cub_offset = np.load('offset.npy')\n",
    "#x_off_base, y_off_base = base_offset\n",
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "\n",
    "utils.default_pos(move)\n",
    "move.Sync()\n",
    "for idx, center in enumerate(centers_cuboids):\n",
    "    if idx == 96:\n",
    "        break # idx is index, enumerate takes an array and assigns indexes to each element of the array, each element in the array is a cuboid\n",
    "    X, Y, _ = tf_mtx @ (center[0], center[1], 1)\n",
    "    move.MovL(X, Y, -89, 0)\n",
    "    move.Sync()\n",
    "    break\n",
    "    # base_angle = utils.get_pose(dash, angle=True, verbose=False)[0]\n",
    "    # x_off, y_off = coordinate_rotation(y_off_base, x_off_base, base_angle)\n",
    "   \n",
    "    # utils.correct_J4_angle(0, dash, move)\n",
    "    # # utils.correct_J4_angle(-360, dash, move)\n",
    "    # # utils.correct_J4_angle(0, dash, move)\n",
    "    # move.RelMovL(0,0,-29)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,29)\n",
    "    # move.Sync()\n",
    "    # x,y = grid[idx]\n",
    "    # move.MovL(x,y,-60, 120)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,-23)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(-100, dash, move)\n",
    "    # move.RelMovL(0,0,23)\n",
    "    # move.Sync()\n",
    "    \n",
    "\n",
    "#utils.default_pos(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8375749a1bafb386f34ea9f0dd7e55daf2784b2541aa2e32281e1f53a27462d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
