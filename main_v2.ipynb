{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deps.dobot_api import DobotApiDashboard, DobotApiMove # deps is a folder and we are importing 2 classes from a file within the folder, these classes \n",
    "# allow us to control the robot informationally and movement oriented \n",
    "from deps import utils # importing the module utils from a file within the folder deps, don't import all files from deps, just utils\n",
    "from deps import cv_core # this module houses all of the functions that are controlling and dealing with the camera and what it's doing\n",
    "import numpy as np # numpy is a module, we want lots of functions from numpy so we import full module\n",
    "import matplotlib.pyplot as plt # module that allows plotting, not used \n",
    "import cv2 # open cv, computer vision module with own GUI\n",
    "from pynput import keyboard # module allows you to get callbacks from keyboard press (control robot using arrow keys)\n",
    "import time # this module allows you to control timings \n",
    "import ipyparallel as ipp # module that allows code to be launched in parallel with other code\n",
    "import random\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = ipp.Cluster(n=1).start_and_connect_sync() # use this to move the robot with arrow keys and view camera feed at the same time \n",
    "e0 = rc[0]\n",
    "e0.block = False\n",
    "e0.activate('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash = DobotApiDashboard('192.168.1.6', 29999) # dash is the object that is connected to the robot and gets information from the dashboard\n",
    "move = DobotApiMove('192.168.1.6', 30003) # the object that allows you to control the movement of the robot\n",
    "# both classes we input ip address and port that we are communicating with \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},EnableRobot();'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.ClearError() # dash is an object and ClearError is a method in dash that we are calling, clears error and warning when robot freezes and turns red\n",
    "dash.EnableRobot() # enables the robot for use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},DisableRobot();'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.DisableRobot() # disables the robot, white letters below is the robot's response as a String, 0 means that everything is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n",
      "Special key pressed: Key.esc\n"
     ]
    }
   ],
   "source": [
    "keys = utils.Keyboard(dash) # initializing the class Keyboard from the module (file that houses functions (methods) and classes utils and we are passing the parameter dash\n",
    "# we are giving the class Keyboard a connection to the robot which is called dash, dash is an object of the class dashboard\n",
    "keys.execute() # Keyboard has a method called execute, use this to record the position of the robot by pressing s. if finished press esc\n",
    "# we want to find corners of well plate so we record the position of the 4 corners and use this information later, just one use of execute of class keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 222.89606 , -148.71013 ,  -35.970783,  -38.637493]),\n",
       " array([230.894862, -89.334341, -35.881607, -26.079063]),\n",
       " array([334.522013, -89.604795, -38.599049, -19.922558]),\n",
       " array([ 327.617359, -150.719381,  -36.98423 ,  -29.632021])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.coords # list of arrays with recorded coordinates at positions where s was pressed, coords is an attribute of keys (a variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [np.array([280,  40, -90,  0]), # list of positions from coords of 4 corners around petri dish, called anchors for the laser\n",
    "           np.array([230,  37, -90,  0]),\n",
    "           np.array([220, -14, -90,  0]),\n",
    "           np.array([270, -15, -90,  0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell calculates the grid for the 96 well plate\n",
    "well_plate = utils.assign_corners(keys.coords, reverse=True) # assign_corners is a method in the module utils \n",
    "left_side_points = np.linspace(well_plate['ul'], well_plate['ll'], 12)[:,:2]\n",
    "right_side_points = np.linspace(well_plate['ur'], well_plate['lr'], 12)[:,:2]\n",
    "grid = []\n",
    "for i in range(len(left_side_points)):\n",
    "    x1, y1 = left_side_points[i]\n",
    "    x2, y2 = right_side_points[i]\n",
    "    a = (x2-x1)/(y2-y1)\n",
    "    b = x1 - a*y1\n",
    "    ys = np.linspace(y1,y2,8) \n",
    "    xs = a*ys + b\n",
    "    grid += (list(zip(xs,ys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('well_plate_96.npy',np.array(grid)) # saves well plate grid into a file named 'well_plate_96.npy', we want to save this so we can use later and not repeat process\n",
    "#np.load('well_plate_96.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x,y \u001b[39m=\u001b[39m coord\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m move\u001b[39m.\u001b[39mMovL(x,y,\u001b[39m-\u001b[39m\u001b[39m60\u001b[39m,\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m move\u001b[39m.\u001b[39;49mSync()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m move\u001b[39m.\u001b[39mMovL(x,y,\u001b[39m-\u001b[39m\u001b[39m80\u001b[39m,\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m move\u001b[39m.\u001b[39mSync()\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:674\u001b[0m, in \u001b[0;36mDobotApiMove.Sync\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSync()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    673\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_data(string)\n\u001b[0;32m--> 674\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_reply()\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:159\u001b[0m, in \u001b[0;36mDobotApi.wait_reply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait_reply\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    Read the return value\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_dobot\u001b[39m.\u001b[39;49mrecv(\u001b[39m1024\u001b[39;49m)\n\u001b[1;32m    160\u001b[0m     data_str \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(data, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m     \u001b[39m#self.log(f'Receive from 192.168.1.6:{self.port}: {data_str}')\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#grid = np.load('well_plate_96.npy')\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "for coord in grid:\n",
    "    x,y = coord\n",
    "    move.MovL(x,y,-60,0)\n",
    "    move.Sync()\n",
    "    move.MovL(x,y,-80,0)\n",
    "    move.Sync()\n",
    "    move.MovL(x,y,-60,0)\n",
    "    move.Sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n",
      "Position saved!\n"
     ]
    }
   ],
   "source": [
    "manmove = utils.ManualMove(move, dash) # used to control robot with keyboard, uses key presses to control robot \n",
    "manmove.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([259.140423, -25.900747, -38.368862,   0.      ]),\n",
       " array([311.43616 , -25.116732, -38.372147,   0.      ]),\n",
       " array([319.415466,  36.8682  , -38.376747,   0.      ]),\n",
       " array([273.618713,  36.862676, -38.382015,   0.      ])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manmove.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_offset = (manmove.coords[0] - np.array([250, 0, -90, 0]))[:2]\n",
    "np.save('base_offset.npy', base_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_rotation(x, y, angle):\n",
    "    xPrime = x*np.cos(angle) - y*np.sin(angle)\n",
    "    yPrime = x*np.sin(angle) + y*np.cos(angle)\n",
    "\n",
    "    return xPrime, yPrime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dash\u001b[39m.\u001b[39;49mClearError()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dash\u001b[39m.\u001b[39mEnableRobot()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/main_v2.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m move\u001b[39m.\u001b[39mMovL(\u001b[39m250\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m90\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:218\u001b[0m, in \u001b[0;36mDobotApiDashboard.ClearError\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mClearError()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_data(string)\n\u001b[0;32m--> 218\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_reply()\n",
      "File \u001b[0;32m~/github/FolchLab_RobotArm/deps/dobot_api.py:159\u001b[0m, in \u001b[0;36mDobotApi.wait_reply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait_reply\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    Read the return value\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_dobot\u001b[39m.\u001b[39;49mrecv(\u001b[39m1024\u001b[39;49m)\n\u001b[1;32m    160\u001b[0m     data_str \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(data, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m     \u001b[39m#self.log(f'Receive from 192.168.1.6:{self.port}: {data_str}')\u001b[39;00m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "move.MovL(250, 0, -90, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_pose(dash, angle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px0\n",
    "from deps import utils\n",
    "from deps.dobot_api import DobotApiDashboard, DobotApiMove\n",
    "dash = DobotApiDashboard('192.168.1.6', 29999)\n",
    "move = DobotApiMove('192.168.1.6', 30003)\n",
    "manmove = utils.ManualMove(move, dash)\n",
    "manmove.execute()\n",
    "coords = manmove.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = e0.pull('coords')\n",
    "coords = ar.get()\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@586.455] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200'])\n",
    "cv_core.video_test(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('anchors.npy', manmove.coords)\n",
    "np.save('anchors_tk.npy', manmove.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = np.load('anchors.npy')\n",
    "np.save('anchors_tk.npy', anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[259.140423, -25.900747, -38.368862,   0.      ],\n",
       "       [311.43616 , -25.116732, -38.372147,   0.      ],\n",
       "       [319.415466,  36.8682  , -38.376747,   0.      ],\n",
       "       [273.618713,  36.862676, -38.382015,   0.      ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Petri Dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1403.793] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@1407.068] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@1409.584] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@1411.832] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "#anchors = keys.coords\n",
    "anchors = np.load('anchors.npy')\n",
    "# anchors = [np.array([307.315193, -13.865066, -81,  -3.484534]),\n",
    "#  np.array([316.442224,  49.591866, -81,  -3.484533]),\n",
    "#  np.array([268.040607,  48.172406, -81,  -3.484533]),\n",
    "#  np.array([260.923249, -14.987419, -81,  -3.484531])]\n",
    "\n",
    "# anchor positions, positions of the laser that the camera recognizes to create a transformation matrix\n",
    "# allows you to transform pixel coordinates of an object to actual robot coordinates \n",
    "\n",
    "# computer vision stuff\n",
    "\n",
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy')\n",
    "dist = np.load('./cam_matrices/dist.npy')\n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy')\n",
    "template = cv2.imread('template.png', 0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap = cv_core.set_res(cap, cv_corfind_contourse.camera_res_dict['1200'])\n",
    "\n",
    "# cv2.namedWindow('frame',  cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "\n",
    "\n",
    "recorded = []\n",
    "for idx, anchor in enumerate(anchors):\n",
    "    x,y,z,r = anchor\n",
    "    move.MovL(x,y,z,r)\n",
    "    move.Sync()\n",
    "\n",
    "    #while(True):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200'])\n",
    "\n",
    "    cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # creating a GUI window cv2 is a module called open cv which has all the methods related to computer vision\n",
    "    cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "    ret, frame = cap.read() # how to access camera information, gives single frame that has been captured by the camera at the time of execution\n",
    "    # gives ret which is a boolean (true/false) true if frame captured, frame gives a numpy array that is basically the image (if color, 3 channel array rgb)\n",
    "    \n",
    "    \n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix) # need these 3 parameters to undistort the frame and give a new undistorted frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    plot_img = frame.copy() # create a copy of the variable frame (create a copy of the image)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # turn frame to grayscale \n",
    "    (minVal, maxVal, minLoc, maxLoc)=cv2.minMaxLoc(gray) # gives location of minimum and maximum pixel value, gives coordinates in pixels\n",
    "    a, b = maxLoc # unpack max location into 2 variables, the x and y (a and b) in pixels\n",
    "    \n",
    "    top_left = (a-w, b-h) # make white rectangle around desired maximum pixel values\n",
    "    bottom_right = (a+w, b+h)\n",
    "\n",
    "    mask = np.zeros_like(frame) # brightest part not always the center point, we want to isolate the bright spot, we apply a mask onto the image \n",
    "    # we take a grayscale image and we apply a mask around the bright spot, we create absolute black image \n",
    "    cv2.rectangle(mask,top_left, bottom_right, (255,255,255), -1) # we create filled white rectangle around the bright spot \n",
    "    cv2.rectangle(plot_img,top_left, bottom_right, (255,255,255), 2) # puts white hollow rectangle onto the visual image \n",
    "    result = cv2.bitwise_and(frame.astype('uint8'), mask.astype('uint8')) # we multiply the frame by the mask which leaves only the bright spot\n",
    "    gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) # result given in rgb and we want to go to grayscale, gives one grayscale array instead of 3 BGR\n",
    "    ret, thresh = cv2.threshold(gray_result,240,255,cv2.THRESH_BINARY) # apply thresholding to take brightest desired pixels and ignore all other values\n",
    "    M = cv2.moments(thresh) # this is what is finding the center by calculating the moments of the bright blob, calculates center of mass of a pixel blob\n",
    "    if M[\"m00\"] != 0:\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cv2.circle(plot_img, (cX, cY), 5, (0, 255, 0), 2) # drawing a circle around the brightest blob for visual purposes \n",
    "        recorded.append((cX, cY)) # we record the x and y pixel values of the center of the blob so we can map the location onto the robots coordinates, at that point\n",
    "        \n",
    "\n",
    "    cv2.imshow('frame',plot_img) # shows the image\n",
    "    #cv2.imwrite(f'anchor_{idx}.jpg', plot_img)\n",
    "    cv2.waitKey(0) # index zero wait key, tells the computer to wait for any key press before continuing execution\n",
    "    cap.release() # releases the camera from control of the computer, disconnects the camera from the computer and empties memory\n",
    "   \n",
    "cv2.destroyAllWindows() # when 4 loop finishes it destroys (closes) the graphical window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_pose(dash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Pipette down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "move.MovL(315.233371,  49.014043, -97.242516,  -1.563194)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the cell that calculates the transformation matrix \n",
    "xys = [(arr[0], arr[1]) for arr in anchors]\n",
    "robot_coor = utils.assign_corners(xys, reverse=True) # assign corners to the robot coordinates at the 4 corner positions \n",
    "pix_coor = utils.assign_corners(recorded) # assign corners to the pixel coordinates at the 4 corner positions \n",
    "\n",
    "features_mm_to_pixels_dict = {} # setting up an empty dictionary to store the mapping of the corners from coordinate to pixel\n",
    "for key, value in robot_coor.items():\n",
    "    features_mm_to_pixels_dict[value] = pix_coor[key]\n",
    "\n",
    "\n",
    "tf_mtx = cv_core.compute_tf_mtx(features_mm_to_pixels_dict) # method of cv_core module that calculates transformation matrix\n",
    "# takes the dictionary and solves the system of linear equations that gives the transformation matrix and gives the actual relation between the pixels and millimeters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "move.JointMovJ(-30,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_z = np.mean(anchors[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.610901749999996"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-37 - (calibration_z + 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43.38909825"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(anchors[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuboid transfer with Snapshot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3590.480] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "77\n",
      "98\n",
      "89\n",
      "89\n",
      "87\n",
      "86\n",
      "90\n",
      "82\n",
      "89\n",
      "82\n",
      "100\n",
      "80\n",
      "107\n",
      "83\n",
      "97\n",
      "95\n",
      "70\n",
      "67\n",
      "68\n",
      "66\n",
      "71\n",
      "65\n",
      "72\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "grid = np.load('well_plate_96.npy')\n",
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "move.JointMovJ(-30,0,0,0)\n",
    "\n",
    "cont = cv_core.Contours() # define class of methods for cuboid detection, initialize class\n",
    "offset = 40 # create smaller inner circle in petri dish to locate cuboids \n",
    "cap = cv2.VideoCapture(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200']) # sets the resolution of the camera to 1200 x 1600\n",
    "\n",
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy') # uploading the camera matrices for the calibration of the camera for undistortion\n",
    "dist = np.load('./cam_matrices/dist.npy') \n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy') \n",
    "\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011) # set resolution of window\n",
    "idx = 0\n",
    "\n",
    "calibration_z = np.mean(anchors[:,2])\n",
    "z_offset = 35\n",
    "\n",
    "while(True): # we want a video stream so we want a while loop to continuously take new images until loop is broken\n",
    "    \n",
    "    for i in range(5):   # TODO: Test with this and see if you still need five presses on the spacebar # Sarmad Hassan\n",
    "        ret, frame = cap.read()\n",
    "    #ret, frame = cap.read() \n",
    "    \n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "\n",
    "    pt = cont.find_contours(frame, 10, offset) # takes the frame and looks for the circle of the petri dish, also looks for the cuboids \n",
    "        \n",
    "    a,b,r = pt # gives the x y coordinates and the radius of the circle\n",
    "    plot_img = frame.copy() # create a copy of the frame so things can be drawn on it without altering original image\n",
    "\n",
    "    cv2.circle(plot_img, (a, b), r, (3, 162, 255), 2) # circles being drawn on image to locate petri dish\n",
    "    cv2.circle(plot_img, (a, b), 1, (0, 0, 255), 3)\n",
    "    cv2.circle(plot_img, (a, b), r - offset, (0, 255, 0), 2) \n",
    "\n",
    "    cv2.drawContours(plot_img, cont.singular, -1,(0,255, 0),2) # two lists of contours (cuboid contours) that we draw on the plotting image\n",
    "    cv2.drawContours(plot_img, cont.clusters, -1,(0,0,255),2) # we do this to distinguish between clusters and cuboids\n",
    "\n",
    "    cv2.putText(plot_img, f\"Found: {len(cont.singular)}\", (25,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2) # how many cuboids it sees\n",
    "\n",
    "    \n",
    "    cv2.imshow('frame',plot_img) # this just displays the image \n",
    "\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == ord('q'): # if you press q, the while loop will break and the video and locating will stop, then the camera is released and windows destroyed\n",
    "        break\n",
    "    elif k == ord('e'):\n",
    "        print(len(cont.singular))\n",
    "        if len(cont.singular) >= 1:\n",
    "            # center = cont.contour_centers(cont.singular)[0]\n",
    "            center = random.choice(cont.contour_centers(cont.singular))\n",
    "            X, Y, _ = tf_mtx @ (center[0], center[1], 1)\n",
    "            move.MovL(X, Y, calibration_z + z_offset, 0)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(0, dash, move)\n",
    "            # utils.correct_J4_angle(-360, dash, move)\n",
    "            # utils.correct_J4_angle(0, dash, move)\n",
    "            move.RelMovL(0,0, -z_offset) #(0,0,-36)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(120, dash, move)\n",
    "            move.RelMovL(0,0,z_offset) #(0,0,36) #24 works!!\n",
    "            move.Sync()\n",
    "            x,y = grid[idx]\n",
    "            idx += 1\n",
    "            move.MovL(x,y,calibration_z + z_offset, 120)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(120, dash, move)\n",
    "            move.RelMovL(0,0,-28) #(0,0,-27)\n",
    "            move.Sync()\n",
    "            utils.correct_J4_angle(-100, dash, move)\n",
    "            move.RelMovL(0,0, 28) #(0,0,-27)\n",
    "            move.Sync()\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2838.987] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cont = cv_core.Contours() # define class of methods for cuboid detection, initialize class\n",
    "offset = 40 # create smaller inner circle in petri dish to locate cuboids \n",
    "cap = cv2.VideoCapture(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1944'])\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    plot_img = frame.copy()\n",
    "    mask = np.zeros_like(frame)\n",
    "\n",
    "    a, b, _ = frame.shape\n",
    "    mask = cv2.circle(mask, (round(b/2), round(a/2)), 700, (255, 255, 255), -1)\n",
    "    masked = cv2.bitwise_and(frame.astype('uint8'), mask.astype('uint8'))\n",
    "\n",
    "    plot_mask = cv2.circle(mask, (round(b/2), round(a/2)), 800, (255, 255, 255), -1)\n",
    "    plot_img = cv2.bitwise_and(plot_img.astype('uint8'), plot_mask.astype('uint8'))\n",
    "    cv2.circle(plot_img, (round(b/2), round(a/2)), 700, (0, 0, 255), 3)\n",
    "    gray = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY_INV,29,5)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    # dilation = cv2.dilate(thresh,kernel,iterations = 1)\n",
    "    # erosion = cv2.erode(thresh,kernel,iterations = 1)\n",
    "    res = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "            res, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = cont.filter_contours(contours, 60, 500)\n",
    "\n",
    "    \n",
    "    cv2.drawContours(plot_img, contours, -1,(0,255, 0),2)\n",
    "    \n",
    "    for c in contours:\n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"]) # the function moments gives a mysterious dictionary with elements of matrix, it seems that you gotta divide one element by another to get x&y\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cv2.putText(plot_img, f\"{cv2.contourArea(c)}\", (cX - 20, cY - 20), # putting the area of the cuboids onto the screen as text next to the cuboid\n",
    "              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('frame',plot_img)\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == ord('q'): # if you press q, the while loop will break and the video and locating will stop, then the camera is released and windows destroyed\n",
    "        break  \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b, _ = frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1944, 2592)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()  \n",
    "cap.release()  \n",
    "cv2.imshow('frame',frame) # this just displays the image \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011) # set resolution of window\n",
    "\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #ret,res = cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV)\n",
    "ret,res = cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV)\n",
    "th3 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY_INV,11,9)\n",
    "\n",
    "cv2.imshow('frame',th3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuboid Recognition and Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@6842.338] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cont = cv_core.Contours() # define class of methods for cuboid detection, initialize class\n",
    "\n",
    "def on_change(val): pass\n",
    "\n",
    "offset = 40 # create smaller inner circle in petri dish to locate cuboids \n",
    "cap = cv2.VideoCapture(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200']) # sets the resolution of the camera to 1200 x 1600\n",
    "\n",
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy') # uploading the camera matrices for the calibration of the camera for undistortion\n",
    "dist = np.load('./cam_matrices/dist.npy') \n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy') \n",
    "\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL) # create window\n",
    "cv2.resizeWindow('frame', 1348, 1011) # set resolution of window\n",
    "cv2.createTrackbar('Manual Lock', 'frame', 0, 1, on_change) # create trackbar between values of 0 and 1, basically a switch (manual lock of the circle recognition)\n",
    "# stops trying to recognize the petri dish (locked) increases performance of more fps because it recognizes a lot of circles which takes time so this locks it \n",
    "# circle recognition needs optimizing \n",
    "cv2.createTrackbar('Mask Offset', 'frame', offset, 150, on_change) # second trackbar allows control of offset which changes the size of the petri dish detection circle\n",
    "cv2.setMouseCallback('frame', cont.mousecallback) # set a callback function for double clicks of the mouse, this allows us to select cuboids by double clicking\n",
    "# initializes a double click response to select a certain contour on the screen \n",
    "\n",
    "idx = 0 \n",
    "prev_point = (0,0,0)\n",
    "while(True): # we want a video stream so we want a while loop to continuously take new images until loop is broken\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "    val = cv2.getTrackbarPos('Manual Lock', 'frame') # checks position of trackbar for manual lock, if trackbar 1, then val = 1, this turns off circle detection\n",
    "    offset = cv2.getTrackbarPos('Mask Offset', 'frame') # the trackbar with the offset, changes the offset value for the circle\n",
    "    if val == 1:\n",
    "        cont.locked = True\n",
    "    else:\n",
    "        cont.locked = False\n",
    "\n",
    "    # if cont.best_circ is None:\n",
    "    #     while cont.best_circ is None:\n",
    "    #         pt = cont.find_contours(frame, 10, offset)\n",
    "    # else:\n",
    "    pt = cont.find_contours(frame, 10, offset) # 10 og,takes the frame and looks for the circle of the petri dish, also looks for the cuboids \n",
    "        \n",
    "    a,b,r = pt # gives the x y coordinates and the radius of the circle\n",
    "    plot_img = frame.copy() # create a copy of the frame so things can be drawn on it without altering original image\n",
    "    cv2.circle(plot_img, (a, b), r, (3, 162, 255), 2) # circles being drawn on image to locate petri dish\n",
    "    cv2.circle(plot_img, (a, b), 1, (0, 0, 255), 3)\n",
    "    cv2.circle(plot_img, (a, b), r - offset, (0, 255, 0), 2)\n",
    "    # print(cont.big_circ[2])\n",
    "    cv2.circle(plot_img, cont.big_circ[:2], int(cont.big_circ[2]), (0, 0, 255), 2)\n",
    "    cv2.putText(plot_img, f\"{cont.big_circ[2]*2}px = 60mm\", (cont.big_circ[0]-25, cont.big_circ[1] - cont.big_circ[2] - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2) # how to decide size of cuboids, use diameter of petri dish being 60 mm to approximate size of cuboids\n",
    "        # just a text sign around the biggest circle of the image (petri dish) saying that this circle is 60 mm\n",
    "    \n",
    "    cv2.drawContours(plot_img, cont.singular, -1,(0,255, 0),2) # two lists of contours (cuboid contours) that we draw on the plotting image\n",
    "    cv2.drawContours(plot_img, cont.clusters, -1,(0,0,255),2) # we do this to distinguish between clusters and cuboids \n",
    "\n",
    "    if cont.selected: # if we selected cuboids with the double click, we draw them in blue\n",
    "        cv2.drawContours(plot_img, cont.selected, -1,(255,0,0),2) # BGR, this is blue contour \n",
    "\n",
    "    for c in cont.singular: # we find the centers of the contours similar to how we found centers with the calibration step\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"]) # the function moments gives a mysterious dictionary with elements of matrix, it seems that you gotta divide one element by another to get x&y\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "        cv2.circle(plot_img, (cX, cY), 2, (0, 0, 255), -1) # just draw a cirlce around the contour \n",
    "        cv2.putText(plot_img, f\"{cX},{cY}\", (cX - 20, cY - 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(plot_img, f\"{cv2.contourArea(c)}\", (cX - 20, cY - 20), # putting the area of the cuboids onto the screen as text next to the cuboid\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
    "    #out.write(with_contours)\n",
    "\n",
    "    for c in cont.clusters: # same thing for clustes as above but no printed text for cuboid area or coordinate\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        # draw the contour and center of the shape on the image\n",
    "        #cv2.drawContours(plot_img, [c], -1, (0, 255, 0), 2)\n",
    "        cv2.circle(plot_img, (cX, cY), 2, (0, 0, 255), -1)\n",
    "        # cv2.putText(plot_img, f\"{cX},{cY}\", (cX - 20, cY - 20),\n",
    "        # cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "\n",
    "        # cv2.putText(plot_img, f\"{cv2.contourArea(c)}\", (cX - 20, cY - 20),\n",
    "        # cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 1)\n",
    "\n",
    "\n",
    "    if prev_point is pt:\n",
    "        idx += 1\n",
    "    else:\n",
    "        idx = 0\n",
    "    prev_point = pt\n",
    "\n",
    "\n",
    "    if idx >= 30: # if circle stays same for awhile then it will show as locked (30 frames the same)\n",
    "        message = 'LOCKED'\n",
    "        color = (0,255,0)\n",
    "    else:\n",
    "        message = 'SEARCHING' # more text messages \n",
    "        color = (0,0,255)\n",
    "\n",
    "    cv2.putText(plot_img, \"TARGET:\", (25,25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2) # text messages, target displays constantly\n",
    "    cv2.putText(plot_img, f\"{message}\", (125,25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2) # displays message locked or searching\n",
    "    cv2.putText(plot_img, f\"Found: {len(cont.singular)}\", (25,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2) # how many cuboids it sees\n",
    "\n",
    "    \n",
    "    cv2.imshow('frame',plot_img) # this just displays the image \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # if you press q, the while loop will break and the video and locating will stop, then the camera is released and windows destroyed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCaptrure(0) # gets access to the camera \n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200'])\n",
    "cv_core.video_test(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},Sync();'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "M = cv2.moments(cont.selected[0])\n",
    "cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "X, Y, _ = tf_mtx @ (cX, cY, 1)\n",
    "move.MovL(X, Y, -38, 0)\n",
    "move.Sync()\n",
    "#utils.correct_J4_angle(0, dash, move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[264.064392, -25.735942, -43.384838,  -9.996752],\n",
       "       [274.047377,  36.497396, -43.389351,  -9.996789],\n",
       "       [324.645768,  37.404662, -43.390736,  -9.996744],\n",
       "       [312.077032, -26.602958, -43.391468,  -9.996742]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manmove = utils.ManualMove(move, dash)\n",
    "manmove.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash.DisableRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.report_error(dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[466, 548]],\n",
       " \n",
       "        [[465, 549]],\n",
       " \n",
       "        [[467, 551]],\n",
       " \n",
       "        [[469, 551]],\n",
       " \n",
       "        [[470, 550]],\n",
       " \n",
       "        [[469, 549]],\n",
       " \n",
       "        [[467, 549]]], dtype=int32),\n",
       " array([[[582, 561]],\n",
       " \n",
       "        [[582, 565]],\n",
       " \n",
       "        [[585, 565]],\n",
       " \n",
       "        [[585, 562]],\n",
       " \n",
       "        [[584, 562]],\n",
       " \n",
       "        [[583, 561]]], dtype=int32),\n",
       " array([[[567, 608]],\n",
       " \n",
       "        [[565, 610]],\n",
       " \n",
       "        [[565, 611]],\n",
       " \n",
       "        [[566, 611]],\n",
       " \n",
       "        [[567, 612]],\n",
       " \n",
       "        [[569, 612]],\n",
       " \n",
       "        [[570, 611]],\n",
       " \n",
       "        [[570, 610]],\n",
       " \n",
       "        [[568, 608]]], dtype=int32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_centers(conts):\n",
    "    centers = []\n",
    "    for i in range(len(conts)):\n",
    "        M = cv2.moments(conts[i])\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        X, Y, _ = tf_mtx @ (cX, cY, 1)\n",
    "        centers.append([X,Y])\n",
    "    return centers        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},DisableRobot();'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.DisableRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "dash.DisableRobot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating min distance between cuboids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mindis(centers):\n",
    "    dis = collections.defaultdict(lambda: np.inf)\n",
    "    for i in range(len(centers)):\n",
    "        x,y = centers[i]\n",
    "        #print(x,y)\n",
    "        for j in range(i+1,len(centers)):\n",
    "            x1,y1 = centers[j]\n",
    "            distance = math.sqrt(abs(x1-x) ** 2 + abs(y1-y) ** 2)\n",
    "            dis[i] = min(dis[i], distance)\n",
    "            dis[j] = min(dis[j],distance)\n",
    "    return list(sorted(dis.items(), key = lambda item : item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont.singular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[289.09515234661256, -22.735844550746975]\n",
      "[310.04383240934936, -12.605545346702314]\n",
      "[314.57397699201465, 21.26800506362534]\n",
      "[311.1511091890732, 23.572631962268915]\n",
      "[305.0646119640994, -15.581007586072516]\n",
      "[304.659466547037, -15.867976399537127]\n",
      "[309.8443812721631, 23.36808840683021]\n",
      "[300.1374986100695, 29.725543110855355]\n",
      "[299.41885098766915, 29.810303253551083]\n",
      "[298.70020336526875, 29.89506339624681]\n",
      "[294.6234442848701, 30.12482753530091]\n",
      "[290.0760803504631, 29.59712445401543]\n",
      "[289.5925593820662, 29.4030878795909]\n",
      "[289.30506517850597, 29.30548587121119]\n",
      "[287.42334885447525, 28.905738299013052]\n",
      "[269.55011660253183, -12.276992611026706]\n",
      "[269.0145796305796, -11.532367256371124]\n",
      "[268.7925448639653, -11.159470857875874]\n",
      "[268.6357937612963, -10.973606379795704]\n",
      "[268.25700789201306, -10.414845503220292]\n",
      "[267.9958732362319, -9.666717821559978]\n",
      "[315.0660197497821, 4.460352809883759]\n",
      "[314.8061155050059, 9.811192782574366]\n",
      "[314.0747275412178, 11.116913898475175]\n",
      "[313.8130655664345, 9.89245059826537]\n",
      "[312.3078500626777, 0.38604789472125844]\n",
      "[312.55817788007903, 8.091714786456507]\n",
      "[311.1709651358258, 0.0897395425773766]\n",
      "[311.36769499266524, 2.8162954177823565]\n",
      "[310.529989972757, -2.5485538629271502]\n",
      "[312.8868812488148, 15.704449439151674]\n",
      "[311.18493588821855, 3.4714908604025823]\n",
      "[310.9621980296014, 1.2142659497376584]\n",
      "[311.70878715678737, 7.893008442692349]\n",
      "[312.0362601145181, 10.903030804357215]\n",
      "[311.0283605585503, 4.314885665772792]\n",
      "[310.3739419620909, 0.2674319243131862]\n",
      "[310.20462629103486, 2.331787702888491]\n",
      "[311.05577474433375, 9.105797319553076]\n",
      "[310.323507915542, 7.123866799003679]\n",
      "[307.7965978764253, -11.694902033660007]\n",
      "[307.70600930270524, -8.408417839544704]\n",
      "[310.1805517922651, 10.033952267619014]\n",
      "[311.2800945599573, 17.280795175828374]\n",
      "[305.9292038507889, -7.397837633452852]\n",
      "[305.8510040724551, -6.647375067122731]\n",
      "[307.2254764753206, 2.5755611499614943]\n",
      "[307.4628881783334, 10.844658687611783]\n",
      "[307.27942598188383, 8.86973282107185]\n",
      "[305.90495357901835, -0.3532033960123755]\n",
      "[306.14218950903046, 7.258363814347881]\n",
      "[302.386399785336, -13.830471794664717]\n",
      "[307.4793197527363, 23.43183458749759]\n",
      "[304.167775335271, 2.2547365087845392]\n",
      "[306.2369966347678, 19.7526074751936]\n",
      "[305.96294586459817, 21.064165802768954]\n",
      "[305.13868427808063, 17.108476858014527]\n",
      "[303.4508854428779, 8.914799924380688]\n",
      "[302.5087968698575, 4.1122138472513186]\n",
      "[305.03605845497566, 24.246043334495084]\n",
      "[301.27903832027613, -1.4455045655478074]\n",
      "[301.1619144257762, 0.337719611237425]\n",
      "[304.3435946073537, 24.519002839940796]\n",
      "[298.17749142004027, -19.144416760390847]\n",
      "[303.9775490794582, 23.85680274331112]\n",
      "[300.4174345745989, 1.5493410457632493]\n",
      "[302.36918043359424, 19.515375534377455]\n",
      "[302.9586669121098, 25.06492185083222]\n",
      "[302.1476729859821, 21.860862914742825]\n",
      "[300.433690376001, 13.478986618359002]\n",
      "[296.0473807816162, -20.016997624133765]\n",
      "[298.221688726228, -0.45126855214468264]\n",
      "[296.1407817233478, -12.782996581608394]\n",
      "[301.1294939106366, 25.699103331424098]\n",
      "[298.80089568536584, 15.52466331957578]\n",
      "[297.1904177634933, 3.292872183161599]\n",
      "[293.4992086117412, -20.613116655426253]\n",
      "[299.5874635667223, 25.115826165815605]\n",
      "[294.87403256060816, -10.075119783761949]\n",
      "[297.8872759361332, 19.45817085996694]\n",
      "[294.1564395762121, -6.045177677325967]\n",
      "[295.7557591137034, 13.325347377903682]\n",
      "[296.42397268955483, 20.097022109898447]\n",
      "[295.20836066536697, 18.578585342214566]\n",
      "[289.4875574222872, -21.22791476407727]\n",
      "[291.217444287669, -2.2314535496777737]\n",
      "[290.90693022334324, 9.318290970413287]\n",
      "[289.0252138993126, 8.91854339821515]\n",
      "[287.154128640661, -0.5925290746685974]\n",
      "[290.545103247465, 24.436818728744626]\n",
      "[289.5251664421123, 21.699755872525472]\n",
      "[289.44714243677925, 23.107748766145647]\n",
      "[288.55724564031493, 18.024031087226206]\n",
      "[284.26345812265816, -11.525603749191404]\n",
      "[288.9119570108285, 25.16743477538131]\n",
      "[284.63424952157305, 6.889915184269412]\n",
      "[285.50042336526906, 20.990858082499457]\n",
      "[285.64548876455456, 25.971136541364643]\n",
      "[282.5182854085425, 10.05661596564174]\n",
      "[282.82098077550063, 18.138681582876956]\n",
      "[281.5772514735264, 9.199211852252631]\n",
      "[281.27684115557764, 9.665040489787955]\n",
      "[280.16737041450915, 14.159643791424358]\n",
      "[277.40832186240124, 6.797687239811651]\n",
      "[277.60575481124357, 12.154364424176805]\n",
      "[275.97313589360914, 14.857571452683615]\n",
      "[273.7524366814649, 17.271474783055993]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "centers = calc_centers(cont.singular)\n",
    "distances = mindis(centers)\n",
    "\n",
    "for i in range(len(distances)):\n",
    "    print(centers[i])\n",
    "    x,y = centers[i]\n",
    "    move.MovL(x, y, -38, 0)\n",
    "    move.Sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launches the cuboid transfer individual selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#centers_cuboids = cont.contour_centers(cont.singular)\n",
    "grid = np.load('well_plate_96.npy')\n",
    "centers_cuboids = cont.contour_centers(cont.selected)\n",
    "#cub_offset = np.load('offset.npy')\n",
    "#x_off_base, y_off_base = base_offset\n",
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "\n",
    "utils.default_pos(move)\n",
    "move.Sync()\n",
    "for idx, center in enumerate(centers_cuboids):\n",
    "    if idx == 96:\n",
    "        break # idx is index, enumerate takes an array and assigns indexes to each element of the array, each element in the array is a cuboid\n",
    "    X, Y, _ = tf_mtx @ (center[0], center[1], 1)\n",
    "    move.MovL(X, Y, -60, 0)\n",
    "    move.Sync()\n",
    "    # base_angle = utils.get_pose(dash, angle=True, verbose=False)[0]\n",
    "    # x_off, y_off = coordinate_rotation(y_off_base, x_off_base, base_angle)\n",
    "   \n",
    "    utils.correct_J4_angle(0, dash, move)\n",
    "    # utils.correct_J4_angle(-360, dash, move)\n",
    "    # utils.correct_J4_angle(0, dash, move)\n",
    "    move.RelMovL(0,0,-29)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,29)\n",
    "    # move.Sync()\n",
    "    # x,y = grid[idx]\n",
    "    # move.MovL(x,y,-60, 120)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,-23)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(-100, dash, move)\n",
    "    # move.RelMovL(0,0,23)\n",
    "    # move.Sync()\n",
    "    \n",
    "\n",
    "# utils.default_pos(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laser test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_cuboids = cont.contour_centers(cont.selected)\n",
    "grid = np.load('well_plate_96.npy')\n",
    "#centers_cuboids = cont.contour_centers(cont.selected)\n",
    "#cub_offset = np.load('offset.npy')\n",
    "#x_off_base, y_off_base = base_offset\n",
    "dash.ResetRobot()\n",
    "dash.ClearError()\n",
    "dash.EnableRobot()\n",
    "\n",
    "utils.default_pos(move)\n",
    "move.Sync()\n",
    "for idx, center in enumerate(centers_cuboids):\n",
    "    if idx == 96:\n",
    "        break # idx is index, enumerate takes an array and assigns indexes to each element of the array, each element in the array is a cuboid\n",
    "    X, Y, _ = tf_mtx @ (center[0], center[1], 1)\n",
    "    move.MovL(X, Y, -89, 0)\n",
    "    move.Sync()\n",
    "    break\n",
    "    # base_angle = utils.get_pose(dash, angle=True, verbose=False)[0]\n",
    "    # x_off, y_off = coordinate_rotation(y_off_base, x_off_base, base_angle)\n",
    "   \n",
    "    # utils.correct_J4_angle(0, dash, move)\n",
    "    # # utils.correct_J4_angle(-360, dash, move)\n",
    "    # # utils.correct_J4_angle(0, dash, move)\n",
    "    # move.RelMovL(0,0,-29)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,29)\n",
    "    # move.Sync()\n",
    "    # x,y = grid[idx]\n",
    "    # move.MovL(x,y,-60, 120)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(120, dash, move)\n",
    "    # move.RelMovL(0,0,-23)\n",
    "    # move.Sync()\n",
    "    # utils.correct_J4_angle(-100, dash, move)\n",
    "    # move.RelMovL(0,0,23)\n",
    "    # move.Sync()\n",
    "    \n",
    "\n",
    "#utils.default_pos(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8375749a1bafb386f34ea9f0dd7e55daf2784b2541aa2e32281e1f53a27462d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
