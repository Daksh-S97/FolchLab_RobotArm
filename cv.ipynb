{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deps import cv_core\n",
    "import cv2\n",
    "import glob\n",
    "from deps.dobot_api import DobotApiDashboard, DobotApiMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.=0 parameter=0.0\n",
      "No.=1 parameter=-1.0\n",
      "No.=2 parameter=-1.0\n",
      "No.=3 parameter=640.0\n",
      "No.=4 parameter=480.0\n",
      "No.=5 parameter=30.0\n",
      "No.=6 parameter=1448695129.0\n",
      "No.=7 parameter=-1.0\n",
      "No.=8 parameter=16.0\n",
      "No.=9 parameter=0.0\n",
      "No.=10 parameter=10.0\n",
      "No.=11 parameter=32.0\n",
      "No.=12 parameter=75.0\n",
      "No.=13 parameter=0.0\n",
      "No.=14 parameter=10.0\n",
      "No.=15 parameter=5000.0\n",
      "No.=16 parameter=1.0\n",
      "No.=17 parameter=-1.0\n",
      "No.=18 parameter=-1.0\n",
      "No.=19 parameter=-1.0\n",
      "No.=20 parameter=3.0\n",
      "No.=21 parameter=3.0\n",
      "No.=22 parameter=100.0\n",
      "No.=23 parameter=4600.0\n",
      "No.=24 parameter=-1.0\n",
      "No.=25 parameter=-1.0\n",
      "No.=26 parameter=-1.0\n",
      "No.=27 parameter=-1.0\n",
      "No.=28 parameter=-1.0\n",
      "No.=29 parameter=-1.0\n",
      "No.=30 parameter=-1.0\n",
      "No.=31 parameter=-1.0\n",
      "No.=32 parameter=1.0\n",
      "No.=33 parameter=-1.0\n",
      "No.=34 parameter=-1.0\n",
      "No.=35 parameter=-1.0\n",
      "No.=36 parameter=-1.0\n",
      "No.=37 parameter=-1.0\n",
      "No.=38 parameter=4.0\n",
      "No.=39 parameter=-1.0\n",
      "No.=40 parameter=-1.0\n",
      "No.=41 parameter=-1.0\n",
      "No.=42 parameter=200.0\n",
      "No.=43 parameter=-1.0\n",
      "No.=44 parameter=1.0\n",
      "No.=45 parameter=4600.0\n",
      "No.=46 parameter=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1529.844] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    }
   ],
   "source": [
    "# Select the camera number , Generally from 0 Start\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set the parameters first , And then read the parameterss\n",
    "for i in range(47):\n",
    "    print(\"No.={} parameter={}\".format(i,cap.get(i)))\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.545] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "libGL error: MESA-LOADER: failed to open radeonsi: /usr/lib/dri/radeonsi_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: radeonsi\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#cap.set(cv2.CAP_PROP_WHITE_BALANCE_RED_V,10)\n",
    "#cap.set(cv2.CAP_PROP_AUTO_WB, 0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@24.604] global /opt/conda/conda-bld/opencv-suite_1656606573658/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, camera_res['1200'])\n",
    "cv_core.video_test(cap)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mm_to_pixels_dict =  {(382.76, -113.37): (499, 412), #bottom left\n",
    "                                (225.27, 94.68): (240, 103), #top right\n",
    "                                (386.5, 91.55): (492, 98), # bottom right\n",
    "                                (221.25, -110.62): (248, 419)} # top left\n",
    "\n",
    "tf_mtx = cv_core.compute_tf_mtx(features_mm_to_pixels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, cv_core.camera_res_dict['1200'])\n",
    "cont = cv_core.Contours()\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    #ret,thresh = cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    #closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    plot_img = frame.copy()\n",
    "    # cv2.circle(plot_img, (a, b), r, (0, 255, 0), 2)\n",
    "    # cv2.circle(plot_img, (a, b), 1, (255, 0, 0), 3)\n",
    "    #with_contours = cv2.drawContours(plot_img, sorted_contours, -1,(0,255, 0),2)\n",
    "\n",
    "    # for c in sorted_contours:\n",
    "    #     # compute the center of the contour\n",
    "    #     M = cv2.moments(c)\n",
    "    #     cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    #     cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    #     # draw the contour and center of the shape on the image\n",
    "    #     #cv2.drawContours(plot_img, [c], -1, (0, 255, 0), 2)\n",
    "    #     cv2.circle(plot_img, (cX, cY), 2, (0, 0, 255), -1)\n",
    "    #     cv2.putText(plot_img, f\"{cX},{cY}\", (cX - 20, cY - 20),\n",
    "    #     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    #out.write(with_contours)\n",
    "\n",
    "    cv2.imshow('frame',opening)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "#out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = sorted(glob.glob('camera_data/raw/*.png'))\n",
    "\n",
    "\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "  \n",
    "# # org\n",
    "# org = (50, 50)\n",
    "  \n",
    "# # fontScale\n",
    "# fontScale = 1\n",
    "   \n",
    "# # Blue color in BGR\n",
    "# color = (0, 255, 0)\n",
    "  \n",
    "# # Line thickness of 2 px\n",
    "# thickness = 2\n",
    "\n",
    "# for idx, image in enumerate(images):\n",
    "#     img = cv2.imread(image)\n",
    "#     img = cv2.putText(img, f'{idx}', org, font, \n",
    "#                    fontScale, color, thickness, cv2.LINE_AA)\n",
    "#     cv2.imwrite(f'camera_data/marked/image{idx}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy')\n",
    "dist = np.load('./cam_matrices/dist.npy')\n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, camera_res['1200'])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "    cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qt: Session management error: Could not open network socket\n"
     ]
    }
   ],
   "source": [
    "cont = cv_core.Contours()\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, camera_res['768'])\n",
    "centers = cont.wait_for_anchors(cap, show = True)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash = DobotApiDashboard('192.168.1.6', 29999)\n",
    "move = DobotApiMove('192.168.1.6', 30003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,{},EnableRobot();'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dash.ClearError()\n",
    "dash.EnableRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy')\n",
    "dist = np.load('./cam_matrices/dist.npy')\n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, camera_res['1200'])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "\n",
    "    cv2.line(frame, (int(frame.shape[1]/2), 0), (int(frame.shape[1]/2), frame.shape[0]), (0, 255, 0), thickness=2)\n",
    "\n",
    "    cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.copy()\n",
    "cv2.imshow('frame',np.split(img,2, axis = 1)[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New circle detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@528.662] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/project/FolchLab_RobotArm/cv.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=4'>5</a>\u001b[0m ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=6'>7</a>\u001b[0m \u001b[39m# img = frame\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=7'>8</a>\u001b[0m \u001b[39m# img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=8'>9</a>\u001b[0m \u001b[39m# img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,5)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=30'>31</a>\u001b[0m \u001b[39m# cv2.circle(plot_img, (a, b), r, (0, 255, 0), 2)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=31'>32</a>\u001b[0m \u001b[39m# cv2.circle(plot_img, (a, b), 1, (255, 0, 0), 3)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=33'>34</a>\u001b[0m img \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39;49mcopy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=34'>35</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000005?line=36'>37</a>\u001b[0m blur \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mGaussianBlur(img,(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m),\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, (1024, 768))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # img = frame\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,5)\n",
    "    # #_,img = cv2.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "    # kernel = np.ones((2,2),np.uint8)\n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    # #img = cv2.Canny(img, 5, 70, 3)\n",
    "\n",
    "    # blurred = cv2.blur(img, (7, 7))\n",
    "\n",
    "    # detected_circles = cv2.HoughCircles(image=blurred,\n",
    "    #                                     method=cv2.HOUGH_GRADIENT,\n",
    "    #                                     dp=1.5,\n",
    "    #                                     minDist=500,\n",
    "    #                                     param1=100,\n",
    "    #                                     param2=50,\n",
    "    #                                     minRadius=50,\n",
    "    #                                     maxRadius=300\n",
    "    #                                     )\n",
    "\n",
    "    # detected_circles = np.uint16(np.around(detected_circles))\n",
    "    # pt = detected_circles[0][0]\n",
    "    # a, b, r = pt\n",
    "    # plot_img = frame.copy()\n",
    "    # cv2.circle(plot_img, (a, b), r, (0, 255, 0), 2)\n",
    "    # cv2.circle(plot_img, (a, b), 1, (255, 0, 0), 3)\n",
    "\n",
    "    img = frame.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(img,(3,3),0)\n",
    "    ret, thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    #ret,thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    #closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    #opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    dilation = cv2.dilate(thresh,kernel,iterations = 3)\n",
    "\n",
    "    blurred = cv2.blur(dilation, (7, 7))\n",
    "    detected_circles = cv2.HoughCircles(image=blurred,\n",
    "                                        method=cv2.HOUGH_GRADIENT,\n",
    "                                        dp=1.2,\n",
    "                                        minDist=500,\n",
    "                                        param1=100,\n",
    "                                        param2=50,\n",
    "                                        minRadius=50,\n",
    "                                        maxRadius=300\n",
    "                                        )\n",
    "\n",
    "    detected_circles = np.uint16(np.around(detected_circles))\n",
    "    pt = detected_circles[0][0]\n",
    "    a, b, r = pt\n",
    "    plot_img = frame.copy()\n",
    "    cv2.circle(plot_img, (a, b), r, (0, 255, 0), 2)\n",
    "    cv2.circle(plot_img, (a, b), 1, (255, 0, 0), 3)\n",
    "\n",
    "    cv2.imshow('frame', plot_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_anchors(inp):\n",
    "    maxx = sorted(np.squeeze(inp), key=lambda x: x[0])\n",
    "\n",
    "    left = maxx[:2]\n",
    "    right = maxx[-2:]\n",
    "\n",
    "    l_sorty = sorted(left, key=lambda x: x[1])\n",
    "    r_sorty = sorted(right, key=lambda x: x[1])\n",
    "\n",
    "    return np.vstack((l_sorty, r_sorty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, (1600, 1200))\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "cameraMatrix = np.load('./cam_matrices/cam_mtx.npy')\n",
    "dist = np.load('./cam_matrices/dist.npy')\n",
    "newCameraMatrix = np.load('./cam_matrices/newcam_mtx.npy')\n",
    "\n",
    "all_anchors = []\n",
    "\n",
    "idx = 1\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detected_circles = cv2.HoughCircles(image=gray,\n",
    "                                        method=cv2.HOUGH_GRADIENT,\n",
    "                                        dp=1,\n",
    "                                        minDist=30,\n",
    "                                        param1=100,\n",
    "                                        param2=40,\n",
    "                                        minRadius=20,\n",
    "                                        maxRadius=40\n",
    "                                        )\n",
    "\n",
    "    plot_img = frame.copy()\n",
    "    if detected_circles is not None:\n",
    "        circles = np.uint16(np.around(detected_circles))\n",
    "        if np.squeeze(circles).shape[0] == 4:\n",
    "            all_anchors.append(sort_anchors(circles))\n",
    "\n",
    "        for i in circles[0,:]:\n",
    "            center = (i[0], i[1])\n",
    "            cv2.circle(plot_img, center, 1, (255, 0 ,0), 3)\n",
    "            radius = i[2]\n",
    "            cv2.circle(plot_img, center, radius, (0, 255 ,0), 3)\n",
    "\n",
    "        cv2.putText(plot_img, f\"Frame {idx}\", (25,25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2)\n",
    "\n",
    "        # for i in all_anchors[0]:\n",
    "        #     center = (int(i[0]), int(i[1]))\n",
    "        #     cv2.circle(plot_img, center, 1, (0, 0 ,255), 3)\n",
    "        #     radius = i[2]\n",
    "        #     cv2.circle(plot_img, center, int(radius), (0, 255 ,0), 3)\n",
    "    idx += 1\n",
    "    cv2.imshow('frame', plot_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "means = np.mean(all_anchors, axis = 0)\n",
    "for i in means:\n",
    "    center = (int(i[0]), int(i[1]))\n",
    "    cv2.circle(plot_img, center, 1, (0, 0 ,255), 3)\n",
    "    radius = i[2]\n",
    "    cv2.circle(plot_img, center, int(radius), (0, 0, 255), 3)\n",
    "cv2.putText(plot_img, \"Captured:\", (25,25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2)\n",
    "cv2.imshow('frame', plot_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plot_img = frame.copy()\n",
    "means = np.mean(all_anchors, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in means:\n",
    "    center = (int(i[0]), int(i[1]))\n",
    "    cv2.circle(plot_img, center, 1, (0, 0 ,255), 3)\n",
    "    radius = i[2]\n",
    "    cv2.circle(plot_img, center, int(radius), (0, 0, 255), 3)\n",
    "cv2.putText(plot_img, \"Captured:\", (25,25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0), 2)\n",
    "cv2.imshow('frame', plot_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'circles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/github/FolchLab_RobotArm/cv.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dobot/github/FolchLab_RobotArm/cv.ipynb#ch0000017?line=0'>1</a>\u001b[0m circles\n",
      "\u001b[0;31mNameError\u001b[0m: name 'circles' is not defined"
     ]
    }
   ],
   "source": [
    "circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 273.86407767,   62.03883495,   33.26213592],\n",
       "       [ 275.37864078, 1125.10679612,   33.2038835 ],\n",
       "       [1336.25242718,   58.73786408,   33.5631068 ],\n",
       "       [1341.26213592, 1123.06796117,   33.26213592]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_anchors, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257.56558026373386, 67.36486517637968)\n",
      "(255.11006325483322, 1132.670260362327)\n",
      "(1322.123750768602, 69.9921855777502)\n",
      "(1321.7842183411121, 1135.4694909602404)\n"
     ]
    }
   ],
   "source": [
    "for i in all_anchors[0]:\n",
    "    center = (i[0], i[1])\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 261.40832698,   71.01608941,   34.45982273],\n",
       "        [ 255.04681563, 1131.99019809,   33.31539715],\n",
       "        [1321.47369292,   69.81050823,   33.01046419],\n",
       "        [1323.36348719, 1134.39922538,   33.47042323]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_anchors = []\n",
    "for frame in all_anchors:\n",
    "    maxx = sorted(np.squeeze(frame), key=lambda x: x[0])\n",
    "\n",
    "    left = maxx[:2]\n",
    "    right = maxx[-2:]\n",
    "\n",
    "    l_sorty = sorted(left, key=lambda x: x[1])\n",
    "    r_sorty = sorted(right, key=lambda x: x[1])\n",
    "\n",
    "    sorted_anchors.append(np.vstack((l_sorty, r_sorty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 320.31578947,   65.05263158,   33.31578947],\n",
       "       [ 336.42105263, 1133.89473684,   33.05263158],\n",
       "       [1386.73684211,   47.78947368,   33.94736842],\n",
       "       [1407.47368421, 1114.63157895,   33.15789474]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sorted_anchors,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 320,   64,   30],\n",
       "       [ 336, 1134,   34],\n",
       "       [1388,   46,   32],\n",
       "       [1408, 1116,   34]], dtype=uint16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxx = sorted(np.squeeze(all_anchors[0]), key=lambda x: x[0])\n",
    "\n",
    "left = maxx[:2]\n",
    "right = maxx[-2:]\n",
    "\n",
    "l_sorty = sorted(left, key=lambda x: x[1])\n",
    "r_sorty = sorted(right, key=lambda x: x[1])\n",
    "\n",
    "np.vstack((l_sorty, r_sorty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('test.png', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.copy()\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,55,7)\n",
    "_,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "kernel = np.ones((2,2),np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "#res = cv2.Canny(closing, 5, 70, 3)\n",
    "\n",
    "blurred = cv2.blur(closing, (7, 7))\n",
    "\n",
    "detected_circles = cv2.HoughCircles(image=blurred,\n",
    "                                    method=cv2.HOUGH_GRADIENT,\n",
    "                                    dp=1.2,\n",
    "                                    minDist=10,\n",
    "                                    param1=50,\n",
    "                                    param2=50,\n",
    "                                    minRadius=0,\n",
    "                                    maxRadius=300\n",
    "                                    )\n",
    "\n",
    "detected_circles = np.uint16(np.around(detected_circles))\n",
    "pt = detected_circles[0][0]\n",
    "a, b, r = pt\n",
    "plot_img = frame.copy()\n",
    "cv2.circle(plot_img, (a, b), r, (0, 255, 0), 2)\n",
    "cv2.circle(plot_img, (a, b), 1, (255, 0, 0), 3)\n",
    "\n",
    "\n",
    "#blurred = cv2.GaussianBlur(res, (5, 5), 0)\n",
    "#closing = cv2.morphologyEx(closing, cv2.MORPH_CLOSE, kernel)\n",
    "#closing = cv2.morphologyEx(closing, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow('frame',plot_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#mop up the dirt\n",
    "# cv2.dilate(g, g, None, 1)\n",
    "# cv2.erode(g, g, None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.copy()\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(3,3),0)\n",
    "ret, thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "#ret,thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "#closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "#opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "dilation = cv2.dilate(thresh,kernel,iterations = 3)\n",
    "\n",
    "blurred = cv2.blur(dilation, (7, 7))\n",
    "detected_circles = cv2.HoughCircles(image=blurred,\n",
    "                                    method=cv2.HOUGH_GRADIENT,\n",
    "                                    dp=1.2,\n",
    "                                    minDist=500,\n",
    "                                    param1=100,\n",
    "                                    param2=50,\n",
    "                                    minRadius=50,\n",
    "                                    maxRadius=300\n",
    "                                    )\n",
    "res = cv2.Canny(erosion, 5, 70, 3)\n",
    "detected_circles = np.uint16(np.around(detected_circles))\n",
    "pt = detected_circles[0][0]\n",
    "a, b, r = pt\n",
    "plot_img = frame.copy()\n",
    "cv2.circle(plot_img, (a, b), r, (0, 255, 0), 2)\n",
    "cv2.circle(plot_img, (a, b), 1, (255, 0, 0), 3)\n",
    "\n",
    "cv2.imshow('frame',blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.copy()\n",
    "#img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))\n",
    "mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))\n",
    "mask = cv2.bitwise_or(mask1, mask2)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))\n",
    "# mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))\n",
    "# mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "# kernel = np.ones((3,3),np.uint8)\n",
    "# erosion = cv2.erode(mask1,kernel,iterations = 1)\n",
    "# kernel = np.ones((2,2),np.uint8)\n",
    "# dilation = cv2.dilate(erosion,kernel,iterations = 4)\n",
    "\n",
    "# kernel = np.ones((2,2),np.uint8)\n",
    "# mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "cv2.imshow('frame', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dobot/project/FolchLab_RobotArm/cv.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000022?line=1'>2</a>\u001b[0m cap \u001b[39m=\u001b[39m cv_core\u001b[39m.\u001b[39mset_res(cap, (\u001b[39m1024\u001b[39m, \u001b[39m768\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000022?line=3'>4</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000022?line=4'>5</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000022?line=6'>7</a>\u001b[0m     img \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dobot/project/FolchLab_RobotArm/cv.ipynb#ch0000022?line=7'>8</a>\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, (1024, 768))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img = frame.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # blur = cv2.GaussianBlur(thresh, (5,5), 0)\n",
    "    # kernel = np.ones((4,4), np.uint8)\n",
    "    # erosion = cv2.erode(blur, kernel, iterations=1)\n",
    "\n",
    "    # kernel = np.ones((3,3),np.uint8)\n",
    "    # #closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    # #opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    # dilation = cv2.dilate(thresh,kernel,iterations = 3)\n",
    "\n",
    "    # blurred = cv2.blur(dilation, (7, 7))\n",
    "    detected_circles = cv2.HoughCircles(image=gray,\n",
    "                                        method=cv2.HOUGH_GRADIENT,\n",
    "                                        dp=1,\n",
    "                                        minDist=30,\n",
    "                                        param1=100,\n",
    "                                        param2=40,\n",
    "                                        minRadius=1,\n",
    "                                        maxRadius=30\n",
    "                                        )\n",
    "\n",
    "    if detected_circles is not None and detected_circles.shape[1] == 96:\n",
    "        break\n",
    "cap.release()\n",
    "plot_img = frame.copy()\n",
    "circles = np.uint16(np.around(detected_circles))\n",
    "for i in circles[0,:]:\n",
    "    center = (i[0], i[1])\n",
    "\n",
    "    cv2.circle(plot_img, center, 1, (255, 0 ,0), 3)\n",
    "    radius = i[2]\n",
    "    cv2.circle(plot_img, center, radius, (0, 255 ,0), 3)\n",
    "\n",
    "cv2.imshow('frame', plot_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = circles[0][:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow('frame', plot_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.copy()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(3,3),0)\n",
    "ret, thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((4,4),np.uint8)\n",
    "erosion = cv2.erode(thresh,kernel,iterations = 1)\n",
    "res = cv2.Canny(erosion, 5, 70, 3)\n",
    "#kernel = np.ones((2,2),np.uint8)\n",
    "#opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "blurred = cv2.blur(res, (5, 5))\n",
    "\n",
    "# contours, hierarchy = cv2.findContours(\n",
    "#             blurred, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "detected_circles = cv2.HoughCircles(image=blurred,\n",
    "                                        method=cv2.HOUGH_GRADIENT,\n",
    "                                        dp=1.2,\n",
    "                                        minDist=25,\n",
    "                                        param1=50,\n",
    "                                        param2=50,\n",
    "                                        minRadius=10,\n",
    "                                        maxRadius=30\n",
    "                                        )\n",
    "\n",
    "plot_img = frame.copy()\n",
    "#with_contours = cv2.drawContours(plot_img, contours, -1,(0,255, 0),2)\n",
    "circles_img = np.uint16(np.around(detected_circles))\n",
    "for i in circles_img[0,:]:\n",
    "    cv2.circle(plot_img,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    cv2.circle(plot_img,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "cv2.imshow('frame', erosion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13336/2487679775.py:22: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
      "  local_max = peak_local_max(distance_map, indices=False, min_distance=20, labels=thresh)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage\n",
    "\n",
    "# Load in image, convert to gray scale, and Otsu's threshold\n",
    "image = frame.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Remove small noise by filtering using contour area\n",
    "cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "for c in cnts:\n",
    "    if cv2.contourArea(c) < 1000:\n",
    "        cv2.drawContours(thresh,[c], 0, (0,0,0), -1)\n",
    "\n",
    "cv2.imshow('thresh', thresh)\n",
    "# Compute Euclidean distance from every binary pixel\n",
    "# to the nearest zero pixel then find peaks\n",
    "distance_map = ndimage.distance_transform_edt(thresh)\n",
    "local_max = peak_local_max(distance_map, indices=False, min_distance=20, labels=thresh)\n",
    "\n",
    "# Perform connected component analysis then apply Watershed\n",
    "markers = ndimage.label(local_max, structure=np.ones((3, 3)))[0]\n",
    "labels = watershed(-distance_map, markers, mask=thresh)\n",
    "\n",
    "# Iterate through unique labels\n",
    "for label in np.unique(labels):\n",
    "    if label == 0:\n",
    "        continue\n",
    "\n",
    "    # Create a mask\n",
    "    mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "    mask[labels == label] = 255\n",
    "\n",
    "    # Find contours and determine contour area\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    cv2.drawContours(image, [c], -1, (36,255,12), -1)\n",
    "\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread('camera_data/raw/image0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x56537ecb3a40) is not the object's thread (0x56537ffd63d0).\n",
      "Cannot move to target thread (0x56537ecb3a40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernel_ = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "#im = cv2.filter2D(frame,-2,kernel_)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "ret,thresh = cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "#closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)#\n",
    "# lab = cv2.cvtColor(frame,cv2.COLOR_BGR2LAB)\n",
    "# l_channel, a1, b1 = cv2.split(lab)\n",
    "\n",
    "# clache = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "# cl = clache.apply(l_channel)\n",
    "# limg = cv2.merge((cl,a1,b1))\n",
    "# enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "result = np.hstack((thresh, opening))\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('frame', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#adjusted = cv2.convertScaleAbs(gray, alpha=1.5)\n",
    "\n",
    "# hsv2 = cv2.cvtColor(adjusted, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# mask1 = cv2.inRange(hsv2, (50,60,70), (60,255,255))\n",
    "# #mask2 = cv2.inRange(adjusted, (175,50,20), (180,255,255))\n",
    "# mask = cv2.bitwise_or(mask1, mask2)\n",
    "#blur = cv2.GaussianBlur(gray,(11,11),0)\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "#ret,thresh = cv2.threshold(gray,125,255,cv2.THRESH_BINARY)\n",
    "#kernel = np.ones((3,3),np.uint8)\n",
    "#closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "#opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)#\n",
    "#dilation = cv2.dilate(thresh,kernel,iterations = 3)\n",
    "\n",
    "#blur2 = cv2.blur(dilation, (7, 7))\n",
    "#blur3 = cv2.blur(closing, (7, 7))\n",
    "\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('frame1', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('frame', thresh)\n",
    "cv2.imshow('frame1', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, (1024, 768))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(3,3),0)\n",
    "    ret,thresh = cv2.threshold(blur,100,255,cv2.THRESH_BINARY)\n",
    "    #ret, thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    #closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    #opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    dilation = cv2.dilate(thresh,kernel,iterations = 3)\n",
    "\n",
    "    blur2 = cv2.blur(dilation, (7, 7))\n",
    "    detected_circles = cv2.HoughCircles(image=blur2,\n",
    "                                        method=cv2.HOUGH_GRADIENT,\n",
    "                                        dp=1.2,\n",
    "                                        minDist=500,\n",
    "                                        param1=100,\n",
    "                                        param2=50,\n",
    "                                        minRadius=50,\n",
    "                                        maxRadius=300\n",
    "                                        )\n",
    "\n",
    "    plot_img = frame.copy()\n",
    "#with_contours = cv2.drawContours(plot_img, contours, -1,(0,255, 0),2)\n",
    "    circles_img = np.uint16(np.around(detected_circles))\n",
    "    for i in circles_img[0,:]:\n",
    "        cv2.circle(plot_img,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "        cv2.circle(plot_img,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "\n",
    "    cv2.imshow('frame', plot_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def on_change(val): pass\n",
    "\n",
    "def callback(): pass\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv_core.set_res(cap, camera_res['1200'])\n",
    "\n",
    "cv2.namedWindow('frame',  cv2.WINDOW_NORMAL)\n",
    "cv2.createTrackbar('slider', 'frame', 0, 255, on_change)\n",
    "#cv2.createButton('Manual Lock', callback, None, cv2.QT_NEW_BUTTONBAR, 1)\n",
    "cv2.resizeWindow('frame', 1348, 1011)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    #val = cv2.getTrackbarPos('slider', 'frame')\n",
    "    \n",
    "    if ret:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        adjusted = cv2.convertScaleAbs(hsv, alpha=3)\n",
    "        mask = cv2.inRange(adjusted, (0,100,255), (35,255,255))\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        dilation = cv2.dilate(opening, np.ones((3,3),np.uint8),iterations = 2)\n",
    "        cv2.imshow('frame', dilation)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8375749a1bafb386f34ea9f0dd7e55daf2784b2541aa2e32281e1f53a27462d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
